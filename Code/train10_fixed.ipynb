{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f26bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¯ FINAL TRAINING - EXACT CALCULATED WEIGHTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob \n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ¯ FINAL TRAINING - EXACT CALCULATED WEIGHTS\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8fa47",
   "metadata": {},
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if not gpus:\n",
    "    print(\"âŒ NO GPU DETECTED\")\n",
    "    print(\"Training will be EXTREMELY slow on CPU\")\n",
    "else:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "    print(f\"âœ… GPU: {len(gpus)} device(s)\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"   GPU {i}: {gpu.name}\")\n",
    "    print(\"âœ… Mixed precision (FP16) enabled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6dab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ CLASS WEIGHTS:\n",
      "   background  :    0.0\n",
      "   human       :    7.0\n",
      "   table       :   17.0\n",
      "   chair       :   16.0\n",
      "   robot       :   36.0\n",
      "   backpack    : 5000.0\n",
      "   free        :    7.0\n",
      "   bottle      :    0.3\n",
      "   unknown     :    0.6\n",
      "\n",
      "Config: Batch=8, Epochs=100, LR=0.0002â†’1e-07\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES  = 9\n",
    "IMG_SIZE     = 128\n",
    "BATCH_SIZE   = 8\n",
    "EPOCHS       = 100\n",
    "LR_INITIAL   = 2e-4\n",
    "LR_MIN       = 1e-7\n",
    "\n",
    "DATASET_PATH = \"/home/frauas/segmentation219_AIS/data/frauas_10classes/tfrecords_9class\"\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"background\", \"human\", \"table\", \"chair\", \"robot\", \n",
    "    \"backpack\", \"free\", \"bottle\", \"unknown\"\n",
    "]\n",
    "\n",
    "CLASS_WEIGHTS = tf.constant([\n",
    "   0.003,   # background - LOWER (was 0.01)\n",
    "    7.0,     # human\n",
    "    17.0,    # table\n",
    "    16.0,    # chair\n",
    "    36.0,    # robot\n",
    "    5000.0,  # backpack - EXTREME â˜¢ï¸ (was 340)\n",
    "    7.0,     # free\n",
    "    0.3,     # bottle\n",
    "    800,     # unknown\n",
    "], dtype=tf.float32)\n",
    "\n",
    "print(\"\\nğŸ”¥ CLASS WEIGHTS:\")\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    print(f\"   {name:<12}: {CLASS_WEIGHTS[i].numpy():>6.1f}\")\n",
    "\n",
    "print(f\"\\nConfig: Batch={BATCH_SIZE}, Epochs={EPOCHS}, LR={LR_INITIAL}â†’{LR_MIN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48639f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Loading datasets...\n",
      "================================================================================\n",
      "Found 1 train TFRecord files\n",
      "Found 1 val TFRecord files\n",
      "\n",
      "âœ… Datasets loaded successfully!\n",
      "\n",
      "ğŸ” Testing dataset integrity...\n",
      "   Train batch shape: (8, 128, 128, 6)\n",
      "   Label shape: (8, 128, 128)\n",
      "   Sample labels: [0 8 7]\n",
      "   Val batch shape: (8, 128, 128, 6)\n",
      "   Label shape: (8, 128, 128)\n",
      "âœ… Dataset test passed!\n",
      "================================================================================\n",
      "Creating backpack-focused dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4b177c8e18c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;31m# Use this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m \u001b[0mtrain_ds_focused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_backpack_focused_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4b177c8e18c5>\u001b[0m in \u001b[0;36mcreate_backpack_focused_dataset\u001b[0;34m(original_train_ds)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# Count samples (optional, for logging)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mbackpack_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackpack_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mregular_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregular_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ… Images with backpack: {backpack_count.numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/segmentation219_AIS/scripts/ais_env/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, initial_state, reduce_func, name)\u001b[0m\n\u001b[1;32m   2855\u001b[0m     return structure.from_compatible_tensor_list(\n\u001b[1;32m   2856\u001b[0m         \u001b[0mstate_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2857\u001b[0;31m         gen_dataset_ops.reduce_dataset(\n\u001b[0m\u001b[1;32m   2858\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2859\u001b[0m             \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/segmentation219_AIS/scripts/ais_env/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mreduce_dataset\u001b[0;34m(input_dataset, initial_state, other_arguments, f, output_types, output_shapes, use_inter_op_parallelism, metadata, name)\u001b[0m\n\u001b[1;32m   6252\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6253\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6254\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6255\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ReduceDataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6256\u001b[0m         \u001b[0mother_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_desc = {\n",
    "    \"rgb\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"x\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"y\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"z\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def remap_labels(label):\n",
    "    remapped = tf.where(label == 8, 7, label)\n",
    "    remapped = tf.where(label == 9, 8, remapped)\n",
    "    remapped = tf.where(label == 7, 7, remapped)\n",
    "    return remapped\n",
    "\n",
    "def parse_example(example):\n",
    "    ex = tf.io.parse_single_example(example, feature_desc)\n",
    "    \n",
    "    rgb = tf.image.decode_jpeg(ex[\"rgb\"], channels=3)\n",
    "    x = tf.image.decode_jpeg(ex[\"x\"], channels=1)\n",
    "    y = tf.image.decode_jpeg(ex[\"y\"], channels=1)\n",
    "    z = tf.image.decode_jpeg(ex[\"z\"], channels=1)\n",
    "    \n",
    "    rgb = tf.image.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
    "    x = tf.image.resize(x, (IMG_SIZE, IMG_SIZE))\n",
    "    y = tf.image.resize(y, (IMG_SIZE, IMG_SIZE))\n",
    "    z = tf.image.resize(z, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    rgb = tf.cast(rgb, tf.float32) / 255.0\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    y = tf.cast(y, tf.float32) / 255.0\n",
    "    z = tf.cast(z, tf.float32) / 255.0\n",
    "    \n",
    "    rgbxyz = tf.concat([rgb, x, y, z], axis=-1)\n",
    "    \n",
    "    label = tf.image.decode_png(ex[\"label\"], channels=1)\n",
    "    label = tf.image.resize(label, (IMG_SIZE, IMG_SIZE), method=\"nearest\")\n",
    "    label = tf.squeeze(label, -1)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    label = remap_labels(label)\n",
    "    label = tf.clip_by_value(label, 0, NUM_CLASSES - 1)\n",
    "    \n",
    "    return rgbxyz, label\n",
    "\n",
    "def augment(rgbxyz, label):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        rgbxyz = tf.image.flip_left_right(rgbxyz)\n",
    "        label = tf.image.flip_left_right(label[..., tf.newaxis])[..., 0]\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        rgbxyz = tf.image.flip_up_down(rgbxyz)\n",
    "        label = tf.image.flip_up_down(label[..., tf.newaxis])[..., 0]\n",
    "\n",
    "    rgb = rgbxyz[..., :3]\n",
    "    xyz = rgbxyz[..., 3:]\n",
    "\n",
    "    rgb = tf.image.random_brightness(rgb, 0.3)\n",
    "    rgb = tf.image.random_contrast(rgb, 0.6, 1.4)\n",
    "    rgb = tf.image.random_saturation(rgb, 0.6, 1.4)\n",
    "    rgb = tf.clip_by_value(rgb, 0.0, 1.0)\n",
    "\n",
    "    rgbxyz = tf.concat([rgb, xyz], axis=-1)\n",
    "    return rgbxyz, label\n",
    "\n",
    "# =========================================================\n",
    "# FIXED LOADING FUNCTION (uses glob instead of list_files)\n",
    "# =========================================================\n",
    "def load_dataset(split, augment_data=False):\n",
    "    \"\"\"\n",
    "    Load dataset using glob.glob() instead of tf.data.Dataset.list_files()\n",
    "    This avoids the hanging issue\n",
    "    \"\"\"\n",
    "    # Use Python glob instead of TF list_files\n",
    "    pattern = os.path.join(DATASET_PATH, split, \"*.tfrecords\")\n",
    "    file_list = glob.glob(pattern)\n",
    "    \n",
    "    if not file_list:\n",
    "        raise ValueError(f\"No TFRecords found at: {pattern}\")\n",
    "    \n",
    "    print(f\"Found {len(file_list)} {split} TFRecord files\")\n",
    "    \n",
    "    # Shuffle file list if training\n",
    "    if split == \"train\":\n",
    "        import random\n",
    "        random.shuffle(file_list)\n",
    "    \n",
    "    # Create dataset directly from file list\n",
    "    ds = tf.data.TFRecordDataset(\n",
    "        file_list,\n",
    "        num_parallel_reads=2  # Read 2 files in parallel\n",
    "    )\n",
    "    \n",
    "    # Parse examples\n",
    "    ds = ds.map(parse_example, num_parallel_calls=4)\n",
    "    \n",
    "    # Apply augmentation if requested\n",
    "    if augment_data:\n",
    "        ds = ds.map(augment, num_parallel_calls=4)\n",
    "    \n",
    "    # Shuffle training data\n",
    "    if split == \"train\":\n",
    "        ds = ds.shuffle(buffer_size=200)\n",
    "    \n",
    "    # Batch and prefetch\n",
    "    ds = ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    ds = ds.prefetch(2)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# =========================================================\n",
    "# LOAD DATASETS\n",
    "# =========================================================\n",
    "print(\"=\"*80)\n",
    "print(\"Loading datasets...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_ds = load_dataset(\"train\", augment_data=True)\n",
    "val_ds = load_dataset(\"val\", augment_data=False)\n",
    "\n",
    "print(\"\\nâœ… Datasets loaded successfully!\")\n",
    "\n",
    "# Test the datasets\n",
    "print(\"\\nğŸ” Testing dataset integrity...\")\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"   Train batch shape: {images.shape}\")\n",
    "    print(f\"   Label shape: {labels.shape}\")\n",
    "    print(f\"   Sample labels: {tf.unique(tf.reshape(labels, [-1]))[0][:10].numpy()}\")\n",
    "\n",
    "for images, labels in val_ds.take(1):\n",
    "    print(f\"   Val batch shape: {images.shape}\")\n",
    "    print(f\"   Label shape: {labels.shape}\")\n",
    "\n",
    "print(\"âœ… Dataset test passed!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "def create_backpack_focused_dataset(original_train_ds):\n",
    "    \"\"\"\n",
    "    Oversample images containing backpack using TF operations\n",
    "    \"\"\"\n",
    "    print(\"Creating backpack-focused dataset...\")\n",
    "    \n",
    "    def has_backpack(images, labels):\n",
    "        \"\"\"Check if this sample contains backpack (class 5)\"\"\"\n",
    "        return tf.reduce_any(tf.equal(labels, 5))\n",
    "    \n",
    "    def not_has_backpack(images, labels):\n",
    "        \"\"\"Check if this sample does NOT contain backpack\"\"\"\n",
    "        return tf.logical_not(tf.reduce_any(tf.equal(labels, 5)))\n",
    "    \n",
    "    # Split dataset into backpack and non-backpack\n",
    "    backpack_ds = original_train_ds.unbatch().filter(\n",
    "        lambda img, lbl: has_backpack(img, lbl)\n",
    "    )\n",
    "    \n",
    "    regular_ds = original_train_ds.unbatch().filter(\n",
    "        lambda img, lbl: not_has_backpack(img, lbl)\n",
    "    )\n",
    "    \n",
    "    # Count samples (optional, for logging)\n",
    "    backpack_count = backpack_ds.reduce(0, lambda x, _: x + 1)\n",
    "    regular_count = regular_ds.reduce(0, lambda x, _: x + 1)\n",
    "    \n",
    "    print(f\"âœ… Images with backpack: {backpack_count.numpy()}\")\n",
    "    print(f\"âœ… Images without backpack: {regular_count.numpy()}\")\n",
    "    \n",
    "    # Oversample backpack images 10x\n",
    "    backpack_ds_repeated = backpack_ds.repeat(10)\n",
    "    \n",
    "    # Combine datasets\n",
    "    combined_ds = backpack_ds_repeated.concatenate(regular_ds)\n",
    "    combined_ds = combined_ds.shuffle(buffer_size=5000)\n",
    "    combined_ds = combined_ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    combined_ds = combined_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return combined_ds\n",
    "\n",
    "# Use this\n",
    "train_ds_focused = create_backpack_focused_dataset(train_ds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4dfe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model: 10,200,513 parameters\n"
     ]
    }
   ],
   "source": [
    "def conv_block(x, filters, dropout_rate=0.0):\n",
    "    x = tf.keras.layers.Conv2D(filters, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    if dropout_rate > 0:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def unet_rgbd():\n",
    "    inputs = tf.keras.Input((IMG_SIZE, IMG_SIZE, 6))\n",
    "\n",
    "    c1 = conv_block(inputs, 48)\n",
    "    p1 = tf.keras.layers.MaxPooling2D()(c1)\n",
    "\n",
    "    c2 = conv_block(p1, 96)\n",
    "    p2 = tf.keras.layers.MaxPooling2D()(c2)\n",
    "\n",
    "    c3 = conv_block(p2, 192)\n",
    "    p3 = tf.keras.layers.MaxPooling2D()(c3)\n",
    "\n",
    "    c4 = conv_block(p3, 384, dropout_rate=0.3)\n",
    "    p4 = tf.keras.layers.MaxPooling2D()(c4)\n",
    "\n",
    "    c5 = conv_block(p4, 384, dropout_rate=0.4)\n",
    "\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(192, 2, strides=2, padding=\"same\")(c5)\n",
    "    u6 = tf.keras.layers.Concatenate()([u6, c4])\n",
    "    c6 = conv_block(u6, 384, dropout_rate=0.3)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(96, 2, strides=2, padding=\"same\")(c6)\n",
    "    u7 = tf.keras.layers.Concatenate()([u7, c3])\n",
    "    c7 = conv_block(u7, 192)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(48, 2, strides=2, padding=\"same\")(c7)\n",
    "    u8 = tf.keras.layers.Concatenate()([u8, c2])\n",
    "    c8 = conv_block(u8, 96)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(24, 2, strides=2, padding=\"same\")(c8)\n",
    "    u9 = tf.keras.layers.Concatenate()([u9, c1])\n",
    "    c9 = conv_block(u9, 48)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(\n",
    "        NUM_CLASSES, 1, activation=\"softmax\", dtype='float32'\n",
    "    )(c9)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model = unet_rgbd()\n",
    "print(f\"âœ… Model: {model.count_params():,} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loss functions defined\n"
     ]
    }
   ],
   "source": [
    "def weighted_focal_loss(y_true, y_pred, gamma=5.0):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    pt = tf.exp(-ce)\n",
    "    focal = (1 - pt) ** gamma\n",
    "\n",
    "    weights = tf.gather(CLASS_WEIGHTS, y_true)\n",
    "    return tf.reduce_mean(weights * focal * ce)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    y_true_oh = tf.one_hot(y_true, NUM_CLASSES)\n",
    "\n",
    "    y_true_fg = y_true_oh[..., 1:]\n",
    "    y_pred_fg = y_pred[..., 1:]\n",
    "\n",
    "    inter = tf.reduce_sum(y_true_fg * y_pred_fg, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true_fg + y_pred_fg, axis=[1, 2, 3])\n",
    "\n",
    "    dice = (2 * inter + smooth) / (union + smooth)\n",
    "\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return weighted_focal_loss(y_true, y_pred) + 5.0 * dice_loss(y_true, y_pred)\n",
    "\n",
    "print(\"âœ… Loss functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model compiled\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(LR_INITIAL),\n",
    "    loss=combined_loss,\n",
    "    run_eagerly=False\n",
    ")\n",
    "\n",
    "print(\"âœ… Model compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673375aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 27ms/step - loss: 5.3958 - val_loss: 5.3133\n",
      "Epoch 2/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 27ms/step - loss: 4.9368 - val_loss: 5.2640\n",
      "Epoch 3/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 26ms/step - loss: 4.8918 - val_loss: 5.1619\n",
      "Epoch 4/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 27ms/step - loss: 4.8968 - val_loss: 5.3008\n",
      "Epoch 5/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 26ms/step - loss: 4.8366 - val_loss: 5.2427\n",
      "Epoch 6/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 26ms/step - loss: 4.7579 - val_loss: 5.1840\n",
      "Epoch 7/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 26ms/step - loss: 4.6742 - val_loss: 5.3194\n",
      "Epoch 8/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 26ms/step - loss: 4.6744 - val_loss: 5.1823\n",
      "Epoch 9/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 26ms/step - loss: 4.7206 - val_loss: 5.0456\n",
      "Epoch 10/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 26ms/step - loss: 4.6355 - val_loss: 5.0019\n",
      "Epoch 11/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 26ms/step - loss: 4.6362 - val_loss: 5.2582\n",
      "Epoch 12/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 26ms/step - loss: 4.6375 - val_loss: 5.0451\n",
      "Epoch 13/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 26ms/step - loss: 4.6002 - val_loss: 5.0463\n",
      "Epoch 14/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 26ms/step - loss: 4.5914 - val_loss: 4.9847\n",
      "Epoch 15/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 26ms/step - loss: 4.5842 - val_loss: 4.9841\n",
      "Epoch 16/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 26ms/step - loss: 4.6261 - val_loss: 4.9922\n",
      "Epoch 17/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 26ms/step - loss: 4.5357 - val_loss: 4.9957\n",
      "Epoch 18/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 26ms/step - loss: 4.5924 - val_loss: 5.0651\n",
      "Epoch 19/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 26ms/step - loss: 4.5165 - val_loss: 5.2049\n",
      "Epoch 20/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 26ms/step - loss: 4.4994 - val_loss: 5.0175\n",
      "Epoch 21/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 27ms/step - loss: 4.4848 - val_loss: 4.8136\n",
      "Epoch 22/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 26ms/step - loss: 4.4895 - val_loss: 5.0331\n",
      "Epoch 23/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 26ms/step - loss: 4.4645 - val_loss: 4.9881\n",
      "Epoch 24/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 26ms/step - loss: 4.4325 - val_loss: 5.1524\n",
      "Epoch 25/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 27ms/step - loss: 4.4200 - val_loss: 4.8576\n",
      "Epoch 26/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 27ms/step - loss: 4.3968 - val_loss: 4.9167\n",
      "Epoch 27/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 27ms/step - loss: 4.3509 - val_loss: 5.3632\n",
      "Epoch 28/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 27ms/step - loss: 4.3420 - val_loss: 4.8507\n",
      "Epoch 29/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 25ms/step - loss: 4.3325 - val_loss: 4.9384\n",
      "Epoch 30/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 27ms/step - loss: 4.3423 - val_loss: 4.9397\n",
      "Epoch 31/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 27ms/step - loss: 4.2974 - val_loss: 4.7620\n",
      "Epoch 32/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 27ms/step - loss: 4.3023 - val_loss: 5.3803\n",
      "Epoch 33/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 27ms/step - loss: 4.2858 - val_loss: 4.9013\n",
      "Epoch 34/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 27ms/step - loss: 4.2849 - val_loss: 4.8315\n",
      "Epoch 35/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 27ms/step - loss: 4.2336 - val_loss: 4.8517\n",
      "Epoch 36/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 27ms/step - loss: 4.2805 - val_loss: 4.7511\n",
      "Epoch 37/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 27ms/step - loss: 4.2033 - val_loss: 4.9478\n",
      "Epoch 38/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 28ms/step - loss: 4.2188 - val_loss: 5.0761\n",
      "Epoch 39/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 27ms/step - loss: 4.3645 - val_loss: 4.6361\n",
      "Epoch 40/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 27ms/step - loss: 4.2331 - val_loss: 4.8630\n",
      "Epoch 41/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 27ms/step - loss: 4.1887 - val_loss: 4.7849\n",
      "Epoch 42/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 27ms/step - loss: 4.1826 - val_loss: 4.7852\n",
      "Epoch 43/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 27ms/step - loss: 4.1621 - val_loss: 4.6761\n",
      "Epoch 44/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 27ms/step - loss: 4.1692 - val_loss: 5.0739\n",
      "Epoch 45/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 27ms/step - loss: 4.1221 - val_loss: 4.9276\n",
      "Epoch 46/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 27ms/step - loss: 4.1453 - val_loss: 4.8779\n",
      "Epoch 47/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 27ms/step - loss: 4.1199 - val_loss: 4.9464\n",
      "Epoch 48/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 27ms/step - loss: 4.1183 - val_loss: 4.6983\n",
      "Epoch 49/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 32ms/step - loss: 4.1021 - val_loss: 4.9184\n",
      "Epoch 50/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 27ms/step - loss: 4.0741 - val_loss: 4.7486\n",
      "Epoch 51/100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds_focused,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004fa221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ¯ FINAL RESULTS (IoU + Accuracy)\n",
      "================================================================================\n",
      "\n",
      "Class        |      IoU |   Accuracy\n",
      "----------------------------------------\n",
      "background   |   0.8511 |     0.8712\n",
      "human        |   0.2410 |     0.4778\n",
      "table        |   0.1084 |     0.2248\n",
      "chair        |   0.1782 |     0.2993\n",
      "robot        |   0.0704 |     0.1698\n",
      "backpack     |   0.0080 |     0.7391\n",
      "free         |   0.3125 |     0.7834\n",
      "bottle       |   0.2942 |     0.5814\n",
      "unknown      |   0.1149 |     0.5262\n",
      "----------------------------------------\n",
      "Mean IoU     |   0.2421\n",
      "Mean Acc     |   0.5192\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(model, dataset):\n",
    "    intersection = np.zeros(NUM_CLASSES)\n",
    "    union = np.zeros(NUM_CLASSES)\n",
    "    correct_pixels = np.zeros(NUM_CLASSES)\n",
    "    total_pixels = np.zeros(NUM_CLASSES)\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images, verbose=0)\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "        labels = labels.numpy()\n",
    "\n",
    "        for c in range(NUM_CLASSES):\n",
    "            pred_c = (preds == c)\n",
    "            label_c = (labels == c)\n",
    "\n",
    "            # IoU components\n",
    "            intersection[c] += np.logical_and(pred_c, label_c).sum()\n",
    "            union[c] += np.logical_or(pred_c, label_c).sum()\n",
    "\n",
    "            # Accuracy components\n",
    "            correct_pixels[c] += np.logical_and(pred_c, label_c).sum()\n",
    "            total_pixels[c] += label_c.sum()\n",
    "\n",
    "    iou = intersection / (union + 1e-7)\n",
    "    accuracy = correct_pixels / (total_pixels + 1e-7)\n",
    "\n",
    "    return iou, accuracy\n",
    "\n",
    "\n",
    "# ğŸ”¹ Compute Metrics\n",
    "iou_scores, acc_scores = compute_metrics(model, val_ds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ FINAL RESULTS (IoU + Accuracy)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Class':<12} | {'IoU':>8} | {'Accuracy':>10}\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    print(f\"{name:<12} | {iou_scores[i]:>8.4f} | {acc_scores[i]:>10.4f}\")\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(f\"{'Mean IoU':<12} | {iou_scores.mean():>8.4f}\")\n",
    "print(f\"{'Mean Acc':<12} | {acc_scores.mean():>8.4f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¯ FINAL TRAINING - EXACT CALCULATED WEIGHTS\n",
      "================================================================================\n",
      "\n",
      "ğŸ”¥ CLASS WEIGHTS:\n",
      "   background  :    0.0\n",
      "   human       :    7.0\n",
      "   table       :   17.0\n",
      "   chair       :   16.0\n",
      "   robot       :   36.0\n",
      "   backpack    : 5000.0\n",
      "   free        :    7.0\n",
      "   laptop      :    0.3\n",
      "   bottle      :  800.0\n",
      "   microwave   :   10.0\n",
      "\n",
      "Config: Batch=8, Epochs=100, LR=0.0002â†’1e-07\n",
      "================================================================================\n",
      "Loading datasets...\n",
      "================================================================================\n",
      "Found 1 train TFRecord files\n",
      "Found 1 val TFRecord files\n",
      "\n",
      "âœ… Datasets loaded successfully!\n",
      "\n",
      "ğŸ” Testing dataset integrity...\n",
      "   Train batch shape: (8, 128, 128, 6)\n",
      "   Label shape: (8, 128, 128)\n",
      "   Sample labels: [0 7 8]\n",
      "   Val batch shape: (8, 128, 128, 6)\n",
      "   Label shape: (8, 128, 128)\n",
      "âœ… Dataset test passed!\n",
      "================================================================================\n",
      "Creating backpack-focused dataset...\n",
      "âœ… Images with backpack: 21\n",
      "âœ… Images without backpack: 9907\n",
      "âœ… Model: 10,200,562 parameters\n",
      "âœ… Loss functions defined\n",
      "âœ… Model compiled\n",
      "Epoch 1/100\n",
      "   1264/Unknown \u001b[1m180s\u001b[0m 23ms/step - loss: 10.4560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frauas/segmentation219_AIS/scripts/ais_env/lib/python3.9/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 27ms/step - loss: 10.4533 - val_loss: 5.6487\n",
      "Epoch 2/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 25ms/step - loss: 5.1582 - val_loss: 5.4284\n",
      "Epoch 3/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 25ms/step - loss: 5.1707 - val_loss: 5.3272\n",
      "Epoch 4/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 26ms/step - loss: 4.9982 - val_loss: 5.3411\n",
      "Epoch 5/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 27ms/step - loss: 4.9883 - val_loss: 5.8568\n",
      "Epoch 6/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 27ms/step - loss: 4.9815 - val_loss: 5.2276\n",
      "Epoch 7/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 26ms/step - loss: 4.9270 - val_loss: 5.2843\n",
      "Epoch 8/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.8885 - val_loss: 5.3735\n",
      "Epoch 9/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.9590 - val_loss: 5.2785\n",
      "Epoch 10/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.8730 - val_loss: 5.2448\n",
      "Epoch 11/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.8691 - val_loss: 5.2621\n",
      "Epoch 12/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 26ms/step - loss: 4.9106 - val_loss: 5.1944\n",
      "Epoch 13/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 26ms/step - loss: 4.8647 - val_loss: 5.3703\n",
      "Epoch 14/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.8511 - val_loss: 5.2387\n",
      "Epoch 15/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.8638 - val_loss: 5.1741\n",
      "Epoch 16/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 26ms/step - loss: 4.8376 - val_loss: 5.3564\n",
      "Epoch 17/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 26ms/step - loss: 5.0420 - val_loss: 5.1786\n",
      "Epoch 18/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.8363 - val_loss: 5.1561\n",
      "Epoch 19/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 26ms/step - loss: 4.8299 - val_loss: 5.1569\n",
      "Epoch 20/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.8244 - val_loss: 5.1791\n",
      "Epoch 21/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 26ms/step - loss: 4.8282 - val_loss: 5.1312\n",
      "Epoch 22/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.8219 - val_loss: 5.2336\n",
      "Epoch 23/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 25ms/step - loss: 4.8310 - val_loss: 5.1687\n",
      "Epoch 24/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.8137 - val_loss: 5.2122\n",
      "Epoch 25/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 25ms/step - loss: 4.8225 - val_loss: 5.2916\n",
      "Epoch 26/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 26ms/step - loss: 4.8133 - val_loss: 5.2106\n",
      "Epoch 27/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 26ms/step - loss: 4.8076 - val_loss: 5.1531\n",
      "Epoch 28/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.7978 - val_loss: 5.2749\n",
      "Epoch 29/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.8076 - val_loss: 5.1976\n",
      "Epoch 30/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.8060 - val_loss: 5.1939\n",
      "Epoch 31/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.7965 - val_loss: 5.3335\n",
      "Epoch 32/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.8001 - val_loss: 5.2612\n",
      "Epoch 33/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.8004 - val_loss: 5.1643\n",
      "Epoch 34/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.7864 - val_loss: 5.1610\n",
      "Epoch 35/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 25ms/step - loss: 4.7997 - val_loss: 5.1353\n",
      "Epoch 36/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.7981 - val_loss: 5.2178\n",
      "Epoch 37/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 26ms/step - loss: 4.8094 - val_loss: 5.1176\n",
      "Epoch 38/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.7854 - val_loss: 5.1094\n",
      "Epoch 39/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 26ms/step - loss: 4.7758 - val_loss: 5.1237\n",
      "Epoch 40/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 26ms/step - loss: 4.7772 - val_loss: 5.1027\n",
      "Epoch 41/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 26ms/step - loss: 4.7667 - val_loss: 5.0787\n",
      "Epoch 42/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 26ms/step - loss: 4.7934 - val_loss: 5.0955\n",
      "Epoch 43/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 27ms/step - loss: 4.7718 - val_loss: 5.1845\n",
      "Epoch 44/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 26ms/step - loss: 4.7765 - val_loss: 5.2708\n",
      "Epoch 45/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 26ms/step - loss: 4.7836 - val_loss: 5.0276\n",
      "Epoch 46/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 26ms/step - loss: 4.7618 - val_loss: 5.0749\n",
      "Epoch 47/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 26ms/step - loss: 4.7547 - val_loss: 5.2704\n",
      "Epoch 48/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 26ms/step - loss: 4.7717 - val_loss: 4.9824\n",
      "Epoch 49/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 26ms/step - loss: 4.7627 - val_loss: 5.3133\n",
      "Epoch 50/100\n",
      "\u001b[1m1264/1264\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 30ms/step - loss: 4.7801 - val_loss: 5.1315\n",
      "Epoch 51/100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob \n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ¯ FINAL TRAINING - EXACT CALCULATED WEIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "NUM_CLASSES  = 10\n",
    "IMG_SIZE     = 128\n",
    "BATCH_SIZE   = 8\n",
    "EPOCHS       = 100\n",
    "LR_INITIAL   = 2e-4\n",
    "LR_MIN       = 1e-7\n",
    "\n",
    "DATASET_PATH = \"/home/frauas/segmentation219_AIS/data/frauas_10classes/tfrecords_9class\"\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"background\", \"human\", \"table\", \"chair\", \"robot\", \n",
    "    \"backpack\", \"free\", \"laptop\",\"bottle\", \"microwave\"\n",
    "]\n",
    "\n",
    "CLASS_WEIGHTS = tf.constant([\n",
    "   0.003,   # background - LOWER (was 0.01)\n",
    "    7.0,     # human\n",
    "    17.0,    # table\n",
    "    16.0,    # chair\n",
    "    36.0,    # robot\n",
    "    5000.0,  # backpack - EXTREME â˜¢ï¸ (was 340)\n",
    "    7.0,     # free\n",
    "    0.3,     # laptop\n",
    "    800,     # bottle\n",
    "    10,       # microwave\n",
    "], dtype=tf.float32)\n",
    "\n",
    "print(\"\\nğŸ”¥ CLASS WEIGHTS:\")\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    print(f\"   {name:<12}: {CLASS_WEIGHTS[i].numpy():>6.1f}\")\n",
    "\n",
    "print(f\"\\nConfig: Batch={BATCH_SIZE}, Epochs={EPOCHS}, LR={LR_INITIAL}â†’{LR_MIN}\")\n",
    "\n",
    "\n",
    "feature_desc = {\n",
    "    \"rgb\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"x\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"y\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"z\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def remap_labels(label):\n",
    "    remapped = tf.where(label == 8, 7, label)\n",
    "    remapped = tf.where(label == 9, 8, remapped)\n",
    "    remapped = tf.where(label == 7, 7, remapped)\n",
    "    return remapped\n",
    "\n",
    "def parse_example(example):\n",
    "    ex = tf.io.parse_single_example(example, feature_desc)\n",
    "    \n",
    "    rgb = tf.image.decode_jpeg(ex[\"rgb\"], channels=3)\n",
    "    x = tf.image.decode_jpeg(ex[\"x\"], channels=1)\n",
    "    y = tf.image.decode_jpeg(ex[\"y\"], channels=1)\n",
    "    z = tf.image.decode_jpeg(ex[\"z\"], channels=1)\n",
    "    \n",
    "    rgb = tf.image.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
    "    x = tf.image.resize(x, (IMG_SIZE, IMG_SIZE))\n",
    "    y = tf.image.resize(y, (IMG_SIZE, IMG_SIZE))\n",
    "    z = tf.image.resize(z, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    rgb = tf.cast(rgb, tf.float32) / 255.0\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    y = tf.cast(y, tf.float32) / 255.0\n",
    "    z = tf.cast(z, tf.float32) / 255.0\n",
    "    \n",
    "    rgbxyz = tf.concat([rgb, x, y, z], axis=-1)\n",
    "    \n",
    "    label = tf.image.decode_png(ex[\"label\"], channels=1)\n",
    "    label = tf.image.resize(label, (IMG_SIZE, IMG_SIZE), method=\"nearest\")\n",
    "    label = tf.squeeze(label, -1)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    label = remap_labels(label)\n",
    "    label = tf.clip_by_value(label, 0, NUM_CLASSES - 1)\n",
    "    \n",
    "    return rgbxyz, label\n",
    "\n",
    "def augment(rgbxyz, label):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        rgbxyz = tf.image.flip_left_right(rgbxyz)\n",
    "        label = tf.image.flip_left_right(label[..., tf.newaxis])[..., 0]\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        rgbxyz = tf.image.flip_up_down(rgbxyz)\n",
    "        label = tf.image.flip_up_down(label[..., tf.newaxis])[..., 0]\n",
    "\n",
    "    rgb = rgbxyz[..., :3]\n",
    "    xyz = rgbxyz[..., 3:]\n",
    "\n",
    "    rgb = tf.image.random_brightness(rgb, 0.3)\n",
    "    rgb = tf.image.random_contrast(rgb, 0.6, 1.4)\n",
    "    rgb = tf.image.random_saturation(rgb, 0.6, 1.4)\n",
    "    rgb = tf.clip_by_value(rgb, 0.0, 1.0)\n",
    "\n",
    "    rgbxyz = tf.concat([rgb, xyz], axis=-1)\n",
    "    return rgbxyz, label\n",
    "\n",
    "# =========================================================\n",
    "# FIXED LOADING FUNCTION (uses glob instead of list_files)\n",
    "# =========================================================\n",
    "def load_dataset(split, augment_data=False):\n",
    "    \"\"\"\n",
    "    Load dataset using glob.glob() instead of tf.data.Dataset.list_files()\n",
    "    This avoids the hanging issue\n",
    "    \"\"\"\n",
    "    # Use Python glob instead of TF list_files\n",
    "    pattern = os.path.join(DATASET_PATH, split, \"*.tfrecords\")\n",
    "    file_list = glob.glob(pattern)\n",
    "    \n",
    "    if not file_list:\n",
    "        raise ValueError(f\"No TFRecords found at: {pattern}\")\n",
    "    \n",
    "    print(f\"Found {len(file_list)} {split} TFRecord files\")\n",
    "    \n",
    "    # Shuffle file list if training\n",
    "    if split == \"train\":\n",
    "        import random\n",
    "        random.shuffle(file_list)\n",
    "    \n",
    "    # Create dataset directly from file list\n",
    "    ds = tf.data.TFRecordDataset(\n",
    "        file_list,\n",
    "        num_parallel_reads=2  # Read 2 files in parallel\n",
    "    )\n",
    "    \n",
    "    # Parse examples\n",
    "    ds = ds.map(parse_example, num_parallel_calls=4)\n",
    "    \n",
    "    # Apply augmentation if requested\n",
    "    if augment_data:\n",
    "        ds = ds.map(augment, num_parallel_calls=4)\n",
    "    \n",
    "    # Shuffle training data\n",
    "    if split == \"train\":\n",
    "        ds = ds.shuffle(buffer_size=200)\n",
    "    \n",
    "    # Batch and prefetch\n",
    "    ds = ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    ds = ds.prefetch(2)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# =========================================================\n",
    "# LOAD DATASETS\n",
    "# =========================================================\n",
    "print(\"=\"*80)\n",
    "print(\"Loading datasets...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_ds = load_dataset(\"train\", augment_data=True)\n",
    "val_ds = load_dataset(\"val\", augment_data=False)\n",
    "\n",
    "print(\"\\nâœ… Datasets loaded successfully!\")\n",
    "\n",
    "# Test the datasets\n",
    "print(\"\\nğŸ” Testing dataset integrity...\")\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"   Train batch shape: {images.shape}\")\n",
    "    print(f\"   Label shape: {labels.shape}\")\n",
    "    print(f\"   Sample labels: {tf.unique(tf.reshape(labels, [-1]))[0][:10].numpy()}\")\n",
    "\n",
    "for images, labels in val_ds.take(1):\n",
    "    print(f\"   Val batch shape: {images.shape}\")\n",
    "    print(f\"   Label shape: {labels.shape}\")\n",
    "\n",
    "print(\"âœ… Dataset test passed!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "def create_backpack_focused_dataset(original_train_ds):\n",
    "    \"\"\"\n",
    "    Oversample images containing backpack using TF operations\n",
    "    \"\"\"\n",
    "    print(\"Creating backpack-focused dataset...\")\n",
    "    \n",
    "    def has_backpack(images, labels):\n",
    "        \"\"\"Check if this sample contains backpack (class 5)\"\"\"\n",
    "        return tf.reduce_any(tf.equal(labels, 5))\n",
    "    \n",
    "    def not_has_backpack(images, labels):\n",
    "        \"\"\"Check if this sample does NOT contain backpack\"\"\"\n",
    "        return tf.logical_not(tf.reduce_any(tf.equal(labels, 5)))\n",
    "    \n",
    "    # Split dataset into backpack and non-backpack\n",
    "    backpack_ds = original_train_ds.unbatch().filter(\n",
    "        lambda img, lbl: has_backpack(img, lbl)\n",
    "    )\n",
    "    \n",
    "    regular_ds = original_train_ds.unbatch().filter(\n",
    "        lambda img, lbl: not_has_backpack(img, lbl)\n",
    "    )\n",
    "    \n",
    "    # Count samples (optional, for logging)\n",
    "    backpack_count = backpack_ds.reduce(0, lambda x, _: x + 1)\n",
    "    regular_count = regular_ds.reduce(0, lambda x, _: x + 1)\n",
    "    \n",
    "    print(f\"âœ… Images with backpack: {backpack_count.numpy()}\")\n",
    "    print(f\"âœ… Images without backpack: {regular_count.numpy()}\")\n",
    "    \n",
    "    # Oversample backpack images 10x\n",
    "    backpack_ds_repeated = backpack_ds.repeat(10)\n",
    "    \n",
    "    # Combine datasets\n",
    "    combined_ds = backpack_ds_repeated.concatenate(regular_ds)\n",
    "    combined_ds = combined_ds.shuffle(buffer_size=5000)\n",
    "    combined_ds = combined_ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    combined_ds = combined_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return combined_ds\n",
    "\n",
    "# Use this\n",
    "train_ds_focused = create_backpack_focused_dataset(train_ds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conv_block(x, filters, dropout_rate=0.0):\n",
    "    x = tf.keras.layers.Conv2D(filters, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    if dropout_rate > 0:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def unet_rgbd():\n",
    "    inputs = tf.keras.Input((IMG_SIZE, IMG_SIZE, 6))\n",
    "\n",
    "    c1 = conv_block(inputs, 48)\n",
    "    p1 = tf.keras.layers.MaxPooling2D()(c1)\n",
    "\n",
    "    c2 = conv_block(p1, 96)\n",
    "    p2 = tf.keras.layers.MaxPooling2D()(c2)\n",
    "\n",
    "    c3 = conv_block(p2, 192)\n",
    "    p3 = tf.keras.layers.MaxPooling2D()(c3)\n",
    "\n",
    "    c4 = conv_block(p3, 384, dropout_rate=0.3)\n",
    "    p4 = tf.keras.layers.MaxPooling2D()(c4)\n",
    "\n",
    "    c5 = conv_block(p4, 384, dropout_rate=0.4)\n",
    "\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(192, 2, strides=2, padding=\"same\")(c5)\n",
    "    u6 = tf.keras.layers.Concatenate()([u6, c4])\n",
    "    c6 = conv_block(u6, 384, dropout_rate=0.3)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(96, 2, strides=2, padding=\"same\")(c6)\n",
    "    u7 = tf.keras.layers.Concatenate()([u7, c3])\n",
    "    c7 = conv_block(u7, 192)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(48, 2, strides=2, padding=\"same\")(c7)\n",
    "    u8 = tf.keras.layers.Concatenate()([u8, c2])\n",
    "    c8 = conv_block(u8, 96)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(24, 2, strides=2, padding=\"same\")(c8)\n",
    "    u9 = tf.keras.layers.Concatenate()([u9, c1])\n",
    "    c9 = conv_block(u9, 48)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(\n",
    "        NUM_CLASSES, 1, activation=\"softmax\", dtype='float32'\n",
    "    )(c9)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model = unet_rgbd()\n",
    "print(f\"âœ… Model: {model.count_params():,} parameters\")\n",
    "\n",
    "\n",
    "def weighted_focal_loss(y_true, y_pred, gamma=5.0):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    pt = tf.exp(-ce)\n",
    "    focal = (1 - pt) ** gamma\n",
    "\n",
    "    weights = tf.gather(CLASS_WEIGHTS, y_true)\n",
    "    return tf.reduce_mean(weights * focal * ce)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    y_true_oh = tf.one_hot(y_true, NUM_CLASSES)\n",
    "\n",
    "    y_true_fg = y_true_oh[..., 1:]\n",
    "    y_pred_fg = y_pred[..., 1:]\n",
    "\n",
    "    inter = tf.reduce_sum(y_true_fg * y_pred_fg, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true_fg + y_pred_fg, axis=[1, 2, 3])\n",
    "\n",
    "    dice = (2 * inter + smooth) / (union + smooth)\n",
    "\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return weighted_focal_loss(y_true, y_pred) + 5.0 * dice_loss(y_true, y_pred)\n",
    "\n",
    "print(\"âœ… Loss functions defined\")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(LR_INITIAL),\n",
    "    loss=combined_loss,\n",
    "    run_eagerly=False\n",
    ")\n",
    "\n",
    "print(\"âœ… Model compiled\")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds_focused,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(model, dataset):\n",
    "    intersection = np.zeros(NUM_CLASSES)\n",
    "    union = np.zeros(NUM_CLASSES)\n",
    "    correct_pixels = np.zeros(NUM_CLASSES)\n",
    "    total_pixels = np.zeros(NUM_CLASSES)\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images, verbose=0)\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "        labels = labels.numpy()\n",
    "\n",
    "        for c in range(NUM_CLASSES):\n",
    "            pred_c = (preds == c)\n",
    "            label_c = (labels == c)\n",
    "\n",
    "            # IoU components\n",
    "            intersection[c] += np.logical_and(pred_c, label_c).sum()\n",
    "            union[c] += np.logical_or(pred_c, label_c).sum()\n",
    "\n",
    "            # Accuracy components\n",
    "            correct_pixels[c] += np.logical_and(pred_c, label_c).sum()\n",
    "            total_pixels[c] += label_c.sum()\n",
    "\n",
    "    iou = intersection / (union + 1e-7)\n",
    "    accuracy = correct_pixels / (total_pixels + 1e-7)\n",
    "\n",
    "    return iou, accuracy\n",
    "\n",
    "\n",
    "# ğŸ”¹ Compute Metrics\n",
    "iou_scores, acc_scores = compute_metrics(model, val_ds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ FINAL RESULTS (IoU + Accuracy)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Class':<12} | {'IoU':>8} | {'Accuracy':>10}\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    print(f\"{name:<12} | {iou_scores[i]:>8.4f} | {acc_scores[i]:>10.4f}\")\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(f\"{'Mean IoU':<12} | {iou_scores.mean():>8.4f}\")\n",
    "print(f\"{'Mean Acc':<12} | {acc_scores.mean():>8.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(CLASS_NAMES, iou_scores)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"IoU per Class\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9aa1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(CLASS_NAMES, iou_scores)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"IoU per Class\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e69daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ”¥ NUCLEAR 70%+ TRAINING WITH AUTO-RESUME\n",
      "================================================================================\n",
      "\n",
      "ğŸ”¥ NUCLEAR CONFIGURATION:\n",
      "   Epochs: 50\n",
      "   Batch size: 16\n",
      "   Learning rate: 5e-05\n",
      "\n",
      "ğŸ”¥ NUCLEAR WEIGHTS:\n",
      "   background  :      0.0\n",
      "   human       :     50.0\n",
      "   table       :     50.0\n",
      "   chair       :     60.0\n",
      "   robot       :    800.0\n",
      "   backpack    :   5000.0\n",
      "   free        :     20.0\n",
      "   laptop      :    120.0\n",
      "   bottle      :     80.0\n",
      "   microwave   :     10.0\n",
      "\n",
      "ğŸ“‚ Loading datasets...\n",
      "âœ… Datasets loaded\n",
      "\n",
      "ğŸ”„ Creating NUCLEAR balanced dataset...\n",
      "âœ… NUCLEAR dataset created\n",
      "\n",
      "ğŸ” Checking for existing checkpoint...\n",
      "âœ… No checkpoint found. Starting fresh training...\n",
      "\n",
      "âœ… Model ready: 10,200,513 parameters\n",
      "   Training from epoch 0 to 50\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ STARTING/RESUMING NUCLEAR TRAINING\n",
      "================================================================================\n",
      "ğŸ’¾ Auto-saves every epoch (crash-safe)\n",
      "ğŸ† Saves best model when new record achieved\n",
      "ğŸ›‘ Stops automatically if 9/9 classes hit 70%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "â° Training started: 09:25:15\n",
      "\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ULTRA-FAST 70%+ TRAINING WITH AUTO-RESUME\n",
    "# 5-10X FASTER than nuclear version\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Enable mixed precision for 2x speedup\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"âš¡ ULTRA-FAST 70%+ TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# =========================================================\n",
    "# FAST CONFIGURATION\n",
    "# =========================================================\n",
    "NUM_CLASSES = 9\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 40  # DOUBLED for speed\n",
    "EPOCHS = 50\n",
    "LR_INITIAL = 1e-4\n",
    "LR_MIN = 1e-8\n",
    "\n",
    "CHECKPOINT_DIR = \"/home/frauas/segmentation219_AIS/checkpoints_fast_70\"\n",
    "DATASET_PATH = \"/home/frauas/segmentation219_AIS/data/frauas_10classes/tfrecords_9class\"\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "LATEST_MODEL = os.path.join(CHECKPOINT_DIR, \"latest.keras\")\n",
    "META_FILE = os.path.join(CHECKPOINT_DIR, \"meta.json\")\n",
    "BEST_MODEL = os.path.join(CHECKPOINT_DIR, \"best.keras\")\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"background\", \"human\", \"table\", \"chair\", \"robot\", \n",
    "    \"backpack\", \"free\", \"laptop\", \"bottle\", \"microwave\"\n",
    "]\n",
    "\n",
    "# BALANCED WEIGHTS (not extreme)\n",
    "CLASS_WEIGHTS = tf.constant([\n",
    "    0.003,      # background\n",
    "    40.0,     # human\n",
    "    40.0,     # table\n",
    "    50.0,     # chair\n",
    "    400.0,    # robot (reduced from 800)\n",
    "    2000.0,   # backpack (reduced from 5000)\n",
    "    20.0,     # free\n",
    "    100.0,    # laptop\n",
    "    60.0,     # bottle\n",
    "    20.0\n",
    "], dtype=tf.float32)\n",
    "\n",
    "print(f\"\\nâš¡ FAST CONFIG:\")\n",
    "print(f\"   Batch: {BATCH_SIZE} (larger = faster)\")\n",
    "print(f\"   Mixed precision: FP16 (2x speedup)\")\n",
    "print(f\"   Reduced oversampling (fewer steps)\")\n",
    "\n",
    "# =========================================================\n",
    "# DATA PIPELINE\n",
    "# =========================================================\n",
    "feature_desc = {\n",
    "    \"rgb\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"x\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"y\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"z\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def remap_labels(label):\n",
    "    remapped = tf.where(label == 8, 7, label)\n",
    "    remapped = tf.where(label == 9, 8, remapped)\n",
    "    return remapped\n",
    "\n",
    "@tf.function  # Speed optimization\n",
    "def parse_example(example):\n",
    "    ex = tf.io.parse_single_example(example, feature_desc)\n",
    "    rgb = tf.image.decode_jpeg(ex[\"rgb\"], channels=3)\n",
    "    x = tf.image.decode_jpeg(ex[\"x\"], channels=1)\n",
    "    y = tf.image.decode_jpeg(ex[\"y\"], channels=1)\n",
    "    z = tf.image.decode_jpeg(ex[\"z\"], channels=1)\n",
    "    rgb = tf.image.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
    "    x = tf.image.resize(x, (IMG_SIZE, IMG_SIZE))\n",
    "    y = tf.image.resize(y, (IMG_SIZE, IMG_SIZE))\n",
    "    z = tf.image.resize(z, (IMG_SIZE, IMG_SIZE))\n",
    "    rgb = tf.cast(rgb, tf.float32) / 255.0\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    y = tf.cast(y, tf.float32) / 255.0\n",
    "    z = tf.cast(z, tf.float32) / 255.0\n",
    "    rgbxyz = tf.concat([rgb, x, y, z], axis=-1)\n",
    "    label = tf.image.decode_png(ex[\"label\"], channels=1)\n",
    "    label = tf.image.resize(label, (IMG_SIZE, IMG_SIZE), method=\"nearest\")\n",
    "    label = tf.squeeze(label, -1)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    label = remap_labels(label)\n",
    "    label = tf.clip_by_value(label, 0, NUM_CLASSES - 1)\n",
    "    return rgbxyz, label\n",
    "\n",
    "@tf.function  # Speed optimization\n",
    "def fast_augment(rgbxyz, label):\n",
    "    # Simplified augmentation for speed\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        rgbxyz = tf.image.flip_left_right(rgbxyz)\n",
    "        label = tf.image.flip_left_right(label[..., tf.newaxis])[..., 0]\n",
    "    \n",
    "    rgb = rgbxyz[..., :3]\n",
    "    xyz = rgbxyz[..., 3:]\n",
    "    \n",
    "    rgb = tf.image.random_brightness(rgb, 0.2)\n",
    "    rgb = tf.image.random_contrast(rgb, 0.8, 1.2)\n",
    "    rgb = tf.clip_by_value(rgb, 0.0, 1.0)\n",
    "    \n",
    "    rgbxyz = tf.concat([rgb, xyz], axis=-1)\n",
    "    return rgbxyz, label\n",
    "\n",
    "def load_dataset(split, augment_data=False):\n",
    "    pattern = os.path.join(DATASET_PATH, split, \"*.tfrecords\")\n",
    "    file_list = glob.glob(pattern)\n",
    "    if not file_list:\n",
    "        raise ValueError(f\"No TFRecords at: {pattern}\")\n",
    "    if split == \"train\":\n",
    "        import random\n",
    "        random.shuffle(file_list)\n",
    "    ds = tf.data.TFRecordDataset(file_list, num_parallel_reads=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if split == \"val\":\n",
    "        ds = ds.cache()\n",
    "    if augment_data:\n",
    "        ds = ds.map(fast_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if split == \"train\":\n",
    "        ds = ds.shuffle(buffer_size=500)\n",
    "    ds = ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "print(\"\\nğŸ“‚ Loading datasets...\")\n",
    "train_ds = load_dataset(\"train\", augment_data=True)\n",
    "val_ds = load_dataset(\"val\", augment_data=False)\n",
    "print(\"âœ… Datasets loaded\")\n",
    "\n",
    "# =========================================================\n",
    "# SMART OVERSAMPLING - REDUCED FOR SPEED\n",
    "# =========================================================\n",
    "print(\"\\nğŸ”„ Creating FAST balanced dataset...\")\n",
    "\n",
    "def has_class(class_id):\n",
    "    def filter_fn(images, labels):\n",
    "        return tf.reduce_any(tf.equal(labels, class_id))\n",
    "    return filter_fn\n",
    "\n",
    "train_ds_unbatched = train_ds.unbatch()\n",
    "\n",
    "backpack_ds = train_ds_unbatched.filter(has_class(5))\n",
    "robot_ds = train_ds_unbatched.filter(has_class(4))\n",
    "human_ds = train_ds_unbatched.filter(has_class(1))\n",
    "bottle_ds = train_ds_unbatched.filter(has_class(8))\n",
    "table_ds = train_ds_unbatched.filter(has_class(2))\n",
    "chair_ds = train_ds_unbatched.filter(has_class(3))\n",
    "\n",
    "regular_ds = train_ds_unbatched.filter(\n",
    "    lambda img, lbl: tf.logical_not(\n",
    "        tf.reduce_any(tf.equal(lbl, 1)) |\n",
    "        tf.reduce_any(tf.equal(lbl, 2)) |\n",
    "        tf.reduce_any(tf.equal(lbl, 3)) |\n",
    "        tf.reduce_any(tf.equal(lbl, 4)) | \n",
    "        tf.reduce_any(tf.equal(lbl, 5)) |\n",
    "        tf.reduce_any(tf.equal(lbl, 8))\n",
    "    )\n",
    ")\n",
    "\n",
    "# SMART OVERSAMPLING - Reduced for speed\n",
    "backpack_repeated = backpack_ds.repeat(15)  # 15x instead of 50x\n",
    "robot_repeated = robot_ds.repeat(12)        # 12x instead of 30x\n",
    "human_repeated = human_ds.repeat(8)         # 8x instead of 15x\n",
    "bottle_repeated = bottle_ds.repeat(6)       # 6x instead of 12x\n",
    "table_repeated = table_ds.repeat(4)         # 4x instead of 8x\n",
    "chair_repeated = chair_ds.repeat(4)         # 4x instead of 8x\n",
    "\n",
    "train_ds_balanced = backpack_repeated.concatenate(robot_repeated)\n",
    "train_ds_balanced = train_ds_balanced.concatenate(human_repeated)\n",
    "train_ds_balanced = train_ds_balanced.concatenate(bottle_repeated)\n",
    "train_ds_balanced = train_ds_balanced.concatenate(table_repeated)\n",
    "train_ds_balanced = train_ds_balanced.concatenate(chair_repeated)\n",
    "train_ds_balanced = train_ds_balanced.concatenate(regular_ds)\n",
    "\n",
    "train_ds_balanced = train_ds_balanced.shuffle(buffer_size=1000)\n",
    "train_ds_balanced = train_ds_balanced.batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_ds_balanced = train_ds_balanced.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"âœ… FAST dataset: 15x backpack, 12x robot, 8x human, 6x bottle\")\n",
    "\n",
    "# =========================================================\n",
    "# LIGHTER MODEL FOR SPEED\n",
    "# =========================================================\n",
    "def conv_block(x, filters, dropout_rate=0.0):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, 3, padding=\"same\", use_bias=False,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, 3, padding=\"same\", use_bias=False,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    if dropout_rate > 0:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def build_unet():\n",
    "    inputs = tf.keras.Input((IMG_SIZE, IMG_SIZE, 6))\n",
    "    \n",
    "    c1 = conv_block(inputs, 48)\n",
    "    p1 = tf.keras.layers.MaxPooling2D()(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, 96)\n",
    "    p2 = tf.keras.layers.MaxPooling2D()(c2)\n",
    "    \n",
    "    c3 = conv_block(p2, 192)\n",
    "    p3 = tf.keras.layers.MaxPooling2D()(c3)\n",
    "    \n",
    "    c4 = conv_block(p3, 256, dropout_rate=0.3)  # Lighter\n",
    "    p4 = tf.keras.layers.MaxPooling2D()(c4)\n",
    "    \n",
    "    c5 = conv_block(p4, 256, dropout_rate=0.4)  # Lighter\n",
    "    \n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(c5)\n",
    "    u6 = tf.keras.layers.Concatenate()([u6, c4])\n",
    "    c6 = conv_block(u6, 256, dropout_rate=0.3)\n",
    "    \n",
    "    u7 = tf.keras.layers.Conv2DTranspose(96, 2, strides=2, padding=\"same\")(c6)\n",
    "    u7 = tf.keras.layers.Concatenate()([u7, c3])\n",
    "    c7 = conv_block(u7, 192, dropout_rate=0.2)\n",
    "    \n",
    "    u8 = tf.keras.layers.Conv2DTranspose(48, 2, strides=2, padding=\"same\")(c7)\n",
    "    u8 = tf.keras.layers.Concatenate()([u8, c2])\n",
    "    c8 = conv_block(u8, 96, dropout_rate=0.1)\n",
    "    \n",
    "    u9 = tf.keras.layers.Conv2DTranspose(24, 2, strides=2, padding=\"same\")(c8)\n",
    "    u9 = tf.keras.layers.Concatenate()([u9, c1])\n",
    "    c9 = conv_block(u9, 48)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(NUM_CLASSES, 1, activation=\"softmax\", dtype='float32')(c9)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# =========================================================\n",
    "# LOSS FUNCTIONS\n",
    "# =========================================================\n",
    "def weighted_focal_loss(y_true, y_pred, gamma=4.0):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    pt = tf.exp(-ce)\n",
    "    focal = (1 - pt) ** gamma\n",
    "    weights = tf.gather(CLASS_WEIGHTS, y_true)\n",
    "    return tf.reduce_mean(weights * focal * ce)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true_oh = tf.one_hot(y_true, NUM_CLASSES)\n",
    "    y_true_fg = y_true_oh[..., 1:]\n",
    "    y_pred_fg = y_pred[..., 1:]\n",
    "    inter = tf.reduce_sum(y_true_fg * y_pred_fg, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true_fg + y_pred_fg, axis=[1, 2, 3])\n",
    "    dice = (2 * inter + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return weighted_focal_loss(y_true, y_pred) + 6.0 * dice_loss(y_true, y_pred)\n",
    "\n",
    "# =========================================================\n",
    "# AUTO-RESUME\n",
    "# =========================================================\n",
    "print(\"\\nğŸ” Checking for checkpoint...\")\n",
    "\n",
    "if os.path.exists(LATEST_MODEL) and os.path.exists(META_FILE):\n",
    "    print(\"âœ… Resuming from checkpoint...\")\n",
    "    model = tf.keras.models.load_model(\n",
    "        LATEST_MODEL,\n",
    "        custom_objects={\n",
    "            \"combined_loss\": combined_loss,\n",
    "            \"weighted_focal_loss\": weighted_focal_loss,\n",
    "            \"dice_loss\": dice_loss\n",
    "        }\n",
    "    )\n",
    "    with open(META_FILE, 'r') as f:\n",
    "        meta = json.load(f)\n",
    "        START_EPOCH = meta.get(\"epoch\", 0)\n",
    "        BEST_COUNT = meta.get(\"best_count\", 0)\n",
    "    print(f\"   From epoch {START_EPOCH}, best: {BEST_COUNT}/9\")\n",
    "else:\n",
    "    print(\"âœ… Starting fresh...\")\n",
    "    model = build_unet()\n",
    "    START_EPOCH = 0\n",
    "    BEST_COUNT = 0\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(LR_INITIAL),\n",
    "    loss=combined_loss,\n",
    "    jit_compile=True  # XLA for speed\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Model: {model.count_params():,} params\")\n",
    "\n",
    "# =========================================================\n",
    "# METRICS\n",
    "# =========================================================\n",
    "def compute_metrics(model, dataset):\n",
    "    intersection = np.zeros(NUM_CLASSES)\n",
    "    union = np.zeros(NUM_CLASSES)\n",
    "    correct_pixels = np.zeros(NUM_CLASSES)\n",
    "    total_pixels = np.zeros(NUM_CLASSES)\n",
    "    \n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images, verbose=0)\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "        labels = labels.numpy()\n",
    "        \n",
    "        for c in range(NUM_CLASSES):\n",
    "            pred_c = (preds == c)\n",
    "            label_c = (labels == c)\n",
    "            intersection[c] += np.logical_and(pred_c, label_c).sum()\n",
    "            union[c] += np.logical_or(pred_c, label_c).sum()\n",
    "            correct_pixels[c] += np.logical_and(pred_c, label_c).sum()\n",
    "            total_pixels[c] += label_c.sum()\n",
    "    \n",
    "    iou = intersection / (union + 1e-7)\n",
    "    accuracy = correct_pixels / (total_pixels + 1e-7)\n",
    "    return iou, accuracy\n",
    "\n",
    "# =========================================================\n",
    "# FAST CALLBACK\n",
    "# =========================================================\n",
    "class FastCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_ds, best_count=0):\n",
    "        super().__init__()\n",
    "        self.val_ds = val_ds\n",
    "        self.best_count = best_count\n",
    "        self.start_time = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = datetime.now()\n",
    "        print(f\"\\nâš¡ Started: {self.start_time.strftime('%H:%M:%S')}\\n\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        actual_epoch = epoch + 1\n",
    "        \n",
    "        # Save every epoch\n",
    "        self.model.save(LATEST_MODEL)\n",
    "        \n",
    "        # Evaluate every 10 epochs\n",
    "        if actual_epoch % 10 == 0:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"ğŸ“Š EPOCH {actual_epoch}/{EPOCHS}\")\n",
    "            \n",
    "            iou_scores, acc_scores = compute_metrics(self.model, self.val_ds)\n",
    "            \n",
    "            count_70 = 0\n",
    "            for i in range(NUM_CLASSES):\n",
    "                if acc_scores[i] >= 0.7:\n",
    "                    count_70 += 1\n",
    "                    print(f\"âœ… {CLASS_NAMES[i]:<12}: {acc_scores[i]*100:>5.1f}%\")\n",
    "                else:\n",
    "                    gap = 70.0 - (acc_scores[i] * 100)\n",
    "                    print(f\"âŒ {CLASS_NAMES[i]:<12}: {acc_scores[i]*100:>5.1f}% (-{gap:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nğŸ¯ {count_70}/9 classes â‰¥70%\", end=\"\")\n",
    "            \n",
    "            if count_70 > self.best_count:\n",
    "                self.best_count = count_70\n",
    "                self.model.save(BEST_MODEL)\n",
    "                print(\" ğŸ‰ NEW RECORD!\")\n",
    "            else:\n",
    "                print()\n",
    "            \n",
    "            if count_70 == 9:\n",
    "                print(\"ğŸ† ALL 9 ACHIEVED! Stopping...\")\n",
    "                self.model.stop_training = True\n",
    "            \n",
    "            gap = logs.get('val_loss', 0) - logs.get('loss', 0)\n",
    "            print(f\"ğŸ“‰ Gap={gap:.2f}\")\n",
    "            \n",
    "            elapsed = (datetime.now() - self.start_time).total_seconds()\n",
    "            print(f\"â±ï¸ {elapsed/60:.1f}min elapsed, ~{(EPOCHS-actual_epoch)*elapsed/actual_epoch/60:.1f}min left\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Save meta\n",
    "        with open(META_FILE, 'w') as f:\n",
    "            json.dump({\n",
    "                \"epoch\": actual_epoch,\n",
    "                \"best_count\": int(self.best_count)\n",
    "            }, f)\n",
    "\n",
    "# =========================================================\n",
    "# TRAINING\n",
    "# =========================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âš¡ STARTING FAST TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(\"Speed optimizations:\")\n",
    "print(\"  ğŸš€ Mixed precision FP16\")\n",
    "print(\"  ğŸš€ Larger batch (40)\")\n",
    "print(\"  ğŸš€ Reduced oversampling\")\n",
    "print(\"  ğŸš€ Lighter model\")\n",
    "print(\"  ğŸš€ XLA compilation\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "callbacks = [\n",
    "    FastCallback(val_ds, best_count=BEST_COUNT),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=15,\n",
    "        min_lr=LR_MIN,\n",
    "        verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "try:\n",
    "    model.fit(\n",
    "        train_ds_balanced,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=50,  # Reduced from 100\n",
    "        epochs=EPOCHS,\n",
    "        initial_epoch=START_EPOCH,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâš ï¸ Interrupted - progress saved!\")\n",
    "\n",
    "# =========================================================\n",
    "# FINAL RESULTS\n",
    "# =========================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "iou_scores, acc_scores = compute_metrics(model, val_ds)\n",
    "\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    status = \"âœ…\" if acc_scores[i] >= 0.7 else \"âŒ\"\n",
    "    print(f\"{status} {name:<12}: {acc_scores[i]*100:>5.1f}%\")\n",
    "\n",
    "classes_pass = np.sum(acc_scores >= 0.7)\n",
    "print(f\"\\nğŸ¯ {classes_pass}/9 classes â‰¥70%\")\n",
    "\n",
    "if classes_pass >= 7:\n",
    "    print(\"ğŸ‰ EXCELLENT!\")\n",
    "elif classes_pass >= 5:\n",
    "    print(\"âœ… GOOD!\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâš¡ COMPLETE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ffa51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ†˜ EMERGENCY FIX - BALANCED TRAINING\n",
      "================================================================================\n",
      "\n",
      "ğŸ”¥ EMERGENCY CONFIGURATION:\n",
      "   Epochs: 150 | Batch: 20 | LR: 0.0001\n",
      "   Starting FRESH (no resume)\n",
      "\n",
      "ğŸ¯ REBALANCED WEIGHTS (Emergency Fix):\n",
      "Class        |      Old |      New | Change\n",
      "--------------------------------------------------\n",
      "background   |      0.0 |      0.5 | â¬†ï¸\n",
      "human        |     10.0 |     15.0 | â¬†ï¸\n",
      "table        |     20.0 |     25.0 | â¬†ï¸\n",
      "chair        |     20.0 |     25.0 | â¬†ï¸\n",
      "robot        |    150.0 |    100.0 | â¬‡ï¸\n",
      "backpack     |   2000.0 |    600.0 | â¬‡ï¸\n",
      "free         |     10.0 |     15.0 | â¬†ï¸\n",
      "laptop       |    120.0 |     80.0 | â¬‡ï¸\n",
      "bottle       |     30.0 |     10.0 | â¬‡ï¸\n",
      "\n",
      "ğŸ“Š Key changes:\n",
      "   âœ… Background: 0.01 â†’ 0.5 (50x increase!) - Fix collapse\n",
      "   âœ… Backpack: 2000 â†’ 600 (Ã·3.3) - Reduce instability\n",
      "   âœ… Laptop: 120 â†’ 80 (Ã·1.5) - Reduce overfitting\n",
      "   âœ… Bottle: 30 â†’ 10 (Ã·3) - Stop hallucination\n",
      "\n",
      "ğŸ“‚ Loading datasets...\n",
      "âœ… Datasets loaded\n",
      "\n",
      "âš ï¸ Skipping backpack oversampling for now (test baseline)\n",
      "\n",
      "ğŸ”¨ Building model with STRONG regularization...\n",
      "ğŸ“ Model: 10,200,513 parameters\n",
      "   L2 regularization: 5e-4 (was 1e-4)\n",
      "   Dropout: up to 0.6 (was 0.5)\n",
      "   Focal gamma: 3.0 (was 6.0)\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ STARTING EMERGENCY FIX TRAINING\n",
      "================================================================================\n",
      "Changes from previous:\n",
      "  ğŸ”§ Background weight: 0.01 â†’ 0.5 (50x)\n",
      "  ğŸ”§ Backpack weight: 2000 â†’ 600 (Ã·3.3)\n",
      "  ğŸ”§ Laptop weight: 120 â†’ 80\n",
      "  ğŸ”§ L2 regularization: 1e-4 â†’ 5e-4 (5x)\n",
      "  ğŸ”§ Dropout: increased to 0.6\n",
      "  ğŸ”§ Focal gamma: 6.0 â†’ 3.0\n",
      "  ğŸ”§ No backpack oversampling (baseline)\n",
      "================================================================================\n",
      "\n",
      "â° Started: 00:52:25\n",
      "\n",
      "Epoch 1/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 59ms/step - loss: 11.8815 - val_loss: 8.9535 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 7.8614 - val_loss: 8.4882 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 52ms/step - loss: 7.1500 - val_loss: 7.3477 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 6.6244 - val_loss: 7.6326 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 6.3421 - val_loss: 6.7215 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 6.1134 - val_loss: 6.5665 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - loss: 5.9535 - val_loss: 6.4562 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 5.8531 - val_loss: 6.7684 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 52ms/step - loss: 5.7586 - val_loss: 6.6435 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 5.6968\n",
      "ğŸ’¾ Checkpoint saved: epoch 10\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 10/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.331 |  0.333 âŒ\n",
      "human        |  0.105 |  0.192 âŒ\n",
      "table        |  0.017 |  0.089 âŒ\n",
      "chair        |  0.238 |  0.330 âŒ\n",
      "robot        |  0.036 |  0.686 âŒ\n",
      "backpack     |  0.025 |  0.142 âŒ\n",
      "free         |  0.297 |  0.738 âœ…\n",
      "laptop       |  0.056 |  0.918 âœ…\n",
      "bottle       |  0.039 |  0.184 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.1271 | Acc=0.4013\n",
      "ğŸ“‰ Train=5.712 | Val=6.175 | Gap=0.463 âœ…\n",
      "â±ï¸ 31s/epoch | 1.2h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 92ms/step - loss: 5.6968 - val_loss: 6.1752 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 5.6169 - val_loss: 6.1744 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 5.5844 - val_loss: 6.1162 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 5.5233 - val_loss: 6.0565 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 5.4852 - val_loss: 6.2778 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - loss: 5.4457 - val_loss: 6.0730 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 5.4054 - val_loss: 6.0297 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 49ms/step - loss: 5.4014 - val_loss: 5.9375 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 5.3543 - val_loss: 6.1127 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 5.3433 - val_loss: 5.8644 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m495/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 5.3337\n",
      "ğŸ’¾ Checkpoint saved: epoch 20\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 20/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.482 |  0.487 âŒ\n",
      "human        |  0.160 |  0.471 âŒ\n",
      "table        |  0.083 |  0.264 âŒ\n",
      "chair        |  0.206 |  0.632 âŒ\n",
      "robot        |  0.088 |  0.468 âŒ\n",
      "backpack     |  0.036 |  0.468 âŒ\n",
      "free         |  0.350 |  0.814 âœ…\n",
      "laptop       |  0.092 |  0.870 âœ…\n",
      "bottle       |  0.047 |  0.503 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.1717 | Acc=0.5529\n",
      "ğŸ“‰ Train=5.352 | Val=5.846 | Gap=0.495 âœ…\n",
      "â±ï¸ 30s/epoch | 1.1h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 90ms/step - loss: 5.3338 - val_loss: 5.8463 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 5.2774 - val_loss: 5.8824 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 5.2779 - val_loss: 6.4366 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - loss: 5.2831 - val_loss: 5.7860 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 5.2478 - val_loss: 5.8733 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 5.2354 - val_loss: 6.1203 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 49ms/step - loss: 5.2198 - val_loss: 6.0760 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - loss: 5.2112 - val_loss: 5.7536 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - loss: 5.1971 - val_loss: 5.8421 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 5.2053 - val_loss: 6.2823 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 5.1780\n",
      "ğŸ’¾ Checkpoint saved: epoch 30\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 30/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.633 |  0.642 âŒ\n",
      "human        |  0.156 |  0.605 âŒ\n",
      "table        |  0.120 |  0.326 âŒ\n",
      "chair        |  0.203 |  0.594 âŒ\n",
      "robot        |  0.115 |  0.373 âŒ\n",
      "backpack     |  0.019 |  0.261 âŒ\n",
      "free         |  0.361 |  0.838 âœ…\n",
      "laptop       |  0.112 |  0.814 âœ…\n",
      "bottle       |  0.064 |  0.382 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.1982 | Acc=0.5373\n",
      "ğŸ“‰ Train=5.178 | Val=6.015 | Gap=0.837 âœ…\n",
      "â±ï¸ 29s/epoch | 1.0h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 86ms/step - loss: 5.1780 - val_loss: 6.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 5.1645 - val_loss: 5.8758 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 5.1446 - val_loss: 6.6653 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 49ms/step - loss: 5.1267 - val_loss: 5.8445 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 5.1281 - val_loss: 5.6866 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 5.0972 - val_loss: 5.7696 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 49ms/step - loss: 5.0795 - val_loss: 5.7882 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 5.0819 - val_loss: 6.5431 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 5.1530 - val_loss: 6.1437 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 5.1032 - val_loss: 5.8528 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 5.1191\n",
      "ğŸ’¾ Checkpoint saved: epoch 40\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 40/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.666 |  0.676 âŒ\n",
      "human        |  0.065 |  0.137 âŒ\n",
      "table        |  0.094 |  0.480 âŒ\n",
      "chair        |  0.189 |  0.616 âŒ\n",
      "robot        |  0.053 |  0.460 âŒ\n",
      "backpack     |  0.018 |  0.325 âŒ\n",
      "free         |  0.341 |  0.884 âœ…\n",
      "laptop       |  0.161 |  0.702 âœ…\n",
      "bottle       |  0.060 |  0.586 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.1829 | Acc=0.5407\n",
      "ğŸ“‰ Train=5.099 | Val=6.469 | Gap=1.370 ğŸŸ¡\n",
      "â±ï¸ 29s/epoch | 0.9h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - loss: 5.1191 - val_loss: 6.4695 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 5.0889 - val_loss: 5.7350 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 5.0180 - val_loss: 6.4009 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 5.0255 - val_loss: 6.7763 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - loss: 5.0372 - val_loss: 6.2766 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 5.0794 - val_loss: 7.4886 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 4.9858 - val_loss: 6.4026 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 4.9855 - val_loss: 7.3335 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 4.9956 - val_loss: 5.7769 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 5.0533\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 5.0534 - val_loss: 6.0805 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4.9431\n",
      "ğŸ’¾ Checkpoint saved: epoch 50\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 50/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.720 |  0.731 âœ…\n",
      "human        |  0.197 |  0.422 âŒ\n",
      "table        |  0.121 |  0.579 âŒ\n",
      "chair        |  0.247 |  0.592 âŒ\n",
      "robot        |  0.133 |  0.475 âŒ\n",
      "backpack     |  0.052 |  0.465 âŒ\n",
      "free         |  0.381 |  0.867 âœ…\n",
      "laptop       |  0.198 |  0.746 âœ…\n",
      "bottle       |  0.074 |  0.644 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.2359 | Acc=0.6132\n",
      "ğŸ“‰ Train=4.929 | Val=6.054 | Gap=1.125 ğŸŸ¡\n",
      "â±ï¸ 29s/epoch | 0.8h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 87ms/step - loss: 4.9431 - val_loss: 6.0543 - learning_rate: 5.0000e-05\n",
      "Epoch 51/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 4.8878 - val_loss: 7.1643 - learning_rate: 5.0000e-05\n",
      "Epoch 52/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 4.8433 - val_loss: 6.6500 - learning_rate: 5.0000e-05\n",
      "Epoch 53/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 4.8805 - val_loss: 7.1713 - learning_rate: 5.0000e-05\n",
      "Epoch 54/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 4.8374 - val_loss: 7.2083 - learning_rate: 5.0000e-05\n",
      "Epoch 55/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 4.8337 - val_loss: 6.7476 - learning_rate: 5.0000e-05\n",
      "Epoch 56/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 4.7868 - val_loss: 6.5837 - learning_rate: 5.0000e-05\n",
      "Epoch 57/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 4.7714 - val_loss: 7.2638 - learning_rate: 5.0000e-05\n",
      "Epoch 58/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - loss: 4.7658 - val_loss: 7.2282 - learning_rate: 5.0000e-05\n",
      "Epoch 59/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - loss: 4.7726 - val_loss: 6.6956 - learning_rate: 5.0000e-05\n",
      "Epoch 60/150\n",
      "\u001b[1m495/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 4.7662\n",
      "ğŸ’¾ Checkpoint saved: epoch 60\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 60/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.838 |  0.856 âœ…\n",
      "human        |  0.231 |  0.353 âŒ\n",
      "table        |  0.144 |  0.573 âŒ\n",
      "chair        |  0.248 |  0.648 âŒ\n",
      "robot        |  0.128 |  0.406 âŒ\n",
      "backpack     |  0.039 |  0.365 âŒ\n",
      "free         |  0.399 |  0.904 âœ…\n",
      "laptop       |  0.240 |  0.659 âŒ\n",
      "bottle       |  0.108 |  0.426 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.2638 | Acc=0.5767\n",
      "ğŸ“‰ Train=4.781 | Val=7.009 | Gap=2.228 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.7h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 4.7662 - val_loss: 7.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 61/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 4.7335 - val_loss: 8.8080 - learning_rate: 5.0000e-05\n",
      "Epoch 62/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 4.7094 - val_loss: 8.5675 - learning_rate: 5.0000e-05\n",
      "Epoch 63/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 56ms/step - loss: 4.7580 - val_loss: 6.7189 - learning_rate: 5.0000e-05\n",
      "Epoch 64/150\n",
      "\u001b[1m495/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4.6904\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 4.6904 - val_loss: 7.1374 - learning_rate: 5.0000e-05\n",
      "Epoch 65/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - loss: 4.6604 - val_loss: 7.5854 - learning_rate: 2.5000e-05\n",
      "Epoch 66/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 4.6218 - val_loss: 8.8987 - learning_rate: 2.5000e-05\n",
      "Epoch 67/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - loss: 4.6046 - val_loss: 7.6279 - learning_rate: 2.5000e-05\n",
      "Epoch 68/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - loss: 4.5758 - val_loss: 7.0642 - learning_rate: 2.5000e-05\n",
      "Epoch 69/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 4.5757 - val_loss: 7.9641 - learning_rate: 2.5000e-05\n",
      "Epoch 70/150\n",
      "\u001b[1m495/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 4.5883\n",
      "ğŸ’¾ Checkpoint saved: epoch 70\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 70/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.842 |  0.860 âœ…\n",
      "human        |  0.303 |  0.447 âŒ\n",
      "table        |  0.206 |  0.731 âœ…\n",
      "chair        |  0.299 |  0.659 âŒ\n",
      "robot        |  0.151 |  0.619 âŒ\n",
      "backpack     |  0.066 |  0.478 âŒ\n",
      "free         |  0.487 |  0.754 âœ…\n",
      "laptop       |  0.282 |  0.624 âŒ\n",
      "bottle       |  0.106 |  0.561 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.3048 | Acc=0.6372\n",
      "ğŸ“‰ Train=4.554 | Val=7.912 | Gap=3.359 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.6h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 88ms/step - loss: 4.5881 - val_loss: 7.9124 - learning_rate: 2.5000e-05\n",
      "Epoch 71/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - loss: 4.5254 - val_loss: 8.0151 - learning_rate: 2.5000e-05\n",
      "Epoch 72/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - loss: 4.4980 - val_loss: 7.8324 - learning_rate: 2.5000e-05\n",
      "Epoch 73/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - loss: 4.5051 - val_loss: 9.3843 - learning_rate: 2.5000e-05\n",
      "Epoch 74/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 4.4752 - val_loss: 8.7180 - learning_rate: 2.5000e-05\n",
      "Epoch 75/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 56ms/step - loss: 4.4689 - val_loss: 7.9294 - learning_rate: 2.5000e-05\n",
      "Epoch 76/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 4.4537 - val_loss: 8.8754 - learning_rate: 2.5000e-05\n",
      "Epoch 77/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 4.4411 - val_loss: 8.0445 - learning_rate: 2.5000e-05\n",
      "Epoch 78/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 49ms/step - loss: 4.4597 - val_loss: 7.9291 - learning_rate: 2.5000e-05\n",
      "Epoch 79/150\n",
      "\u001b[1m495/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 4.4119\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 4.4118 - val_loss: 8.5310 - learning_rate: 2.5000e-05\n",
      "Epoch 80/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 4.3273\n",
      "ğŸ’¾ Checkpoint saved: epoch 80\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 80/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.843 |  0.863 âœ…\n",
      "human        |  0.338 |  0.557 âŒ\n",
      "table        |  0.255 |  0.683 âŒ\n",
      "chair        |  0.321 |  0.646 âŒ\n",
      "robot        |  0.157 |  0.746 âœ…\n",
      "backpack     |  0.065 |  0.534 âŒ\n",
      "free         |  0.523 |  0.779 âœ…\n",
      "laptop       |  0.313 |  0.538 âŒ\n",
      "bottle       |  0.103 |  0.641 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.3240 | Acc=0.6651\n",
      "ğŸ“‰ Train=4.326 | Val=9.222 | Gap=4.895 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.6h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 87ms/step - loss: 4.3273 - val_loss: 9.2217 - learning_rate: 1.2500e-05\n",
      "Epoch 81/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 4.3199 - val_loss: 8.5648 - learning_rate: 1.2500e-05\n",
      "Epoch 82/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 4.2915 - val_loss: 8.4789 - learning_rate: 1.2500e-05\n",
      "Epoch 83/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 4.2693 - val_loss: 9.1460 - learning_rate: 1.2500e-05\n",
      "Epoch 84/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - loss: 4.2533 - val_loss: 8.8637 - learning_rate: 1.2500e-05\n",
      "Epoch 85/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 4.2498 - val_loss: 10.8774 - learning_rate: 1.2500e-05\n",
      "Epoch 86/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 4.2193 - val_loss: 8.1072 - learning_rate: 1.2500e-05\n",
      "Epoch 87/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 4.2224 - val_loss: 9.4889 - learning_rate: 1.2500e-05\n",
      "Epoch 88/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 4.2140 - val_loss: 9.8771 - learning_rate: 1.2500e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 4.1982 - val_loss: 9.4602 - learning_rate: 1.2500e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 4.1576\n",
      "ğŸ’¾ Checkpoint saved: epoch 90\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 90/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.862 |  0.882 âœ…\n",
      "human        |  0.356 |  0.684 âŒ\n",
      "table        |  0.301 |  0.620 âŒ\n",
      "chair        |  0.326 |  0.655 âŒ\n",
      "robot        |  0.172 |  0.786 âœ…\n",
      "backpack     |  0.058 |  0.577 âŒ\n",
      "free         |  0.521 |  0.818 âœ…\n",
      "laptop       |  0.324 |  0.551 âŒ\n",
      "bottle       |  0.116 |  0.592 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.3374 | Acc=0.6850\n",
      "ğŸ“‰ Train=4.153 | Val=9.667 | Gap=5.514 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.5h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 77ms/step - loss: 4.1576 - val_loss: 9.6672 - learning_rate: 1.2500e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 49ms/step - loss: 4.1506 - val_loss: 10.0260 - learning_rate: 1.2500e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 4.1451 - val_loss: 10.1547 - learning_rate: 1.2500e-05\n",
      "Epoch 93/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - loss: 4.1534 - val_loss: 9.9997 - learning_rate: 1.2500e-05\n",
      "Epoch 94/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 4.0929\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - loss: 4.0929 - val_loss: 10.0469 - learning_rate: 1.2500e-05\n",
      "Epoch 95/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 56ms/step - loss: 4.0418 - val_loss: 10.2766 - learning_rate: 6.2500e-06\n",
      "Epoch 96/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 3.9996 - val_loss: 9.5661 - learning_rate: 6.2500e-06\n",
      "Epoch 97/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 4.0173 - val_loss: 10.2871 - learning_rate: 6.2500e-06\n",
      "Epoch 98/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - loss: 4.0167 - val_loss: 9.8178 - learning_rate: 6.2500e-06\n",
      "Epoch 99/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.9866 - val_loss: 11.0957 - learning_rate: 6.2500e-06\n",
      "Epoch 100/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.9769\n",
      "ğŸ’¾ Checkpoint saved: epoch 100\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 100/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.867 |  0.890 âœ…\n",
      "human        |  0.400 |  0.708 âœ…\n",
      "table        |  0.342 |  0.598 âŒ\n",
      "chair        |  0.348 |  0.620 âŒ\n",
      "robot        |  0.205 |  0.757 âœ…\n",
      "backpack     |  0.046 |  0.516 âŒ\n",
      "free         |  0.525 |  0.822 âœ…\n",
      "laptop       |  0.328 |  0.512 âŒ\n",
      "bottle       |  0.115 |  0.593 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.3530 | Acc=0.6684\n",
      "ğŸ“‰ Train=3.967 | Val=10.920 | Gap=6.953 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.4h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 87ms/step - loss: 3.9769 - val_loss: 10.9199 - learning_rate: 6.2500e-06\n",
      "Epoch 101/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - loss: 3.9691 - val_loss: 10.4819 - learning_rate: 6.2500e-06\n",
      "Epoch 102/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 3.9621 - val_loss: 10.6419 - learning_rate: 6.2500e-06\n",
      "Epoch 103/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 3.9413 - val_loss: 10.5787 - learning_rate: 6.2500e-06\n",
      "Epoch 104/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 3.9348 - val_loss: 10.2991 - learning_rate: 6.2500e-06\n",
      "Epoch 105/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 3.9158 - val_loss: 9.9899 - learning_rate: 6.2500e-06\n",
      "Epoch 106/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 3.8965 - val_loss: 11.2540 - learning_rate: 6.2500e-06\n",
      "Epoch 107/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 3.8891 - val_loss: 10.7856 - learning_rate: 6.2500e-06\n",
      "Epoch 108/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.8740 - val_loss: 11.5275 - learning_rate: 6.2500e-06\n",
      "Epoch 109/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 3.8699\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.8700 - val_loss: 10.5600 - learning_rate: 6.2500e-06\n",
      "Epoch 110/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.8440\n",
      "ğŸ’¾ Checkpoint saved: epoch 110\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 110/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.868 |  0.889 âœ…\n",
      "human        |  0.392 |  0.767 âœ…\n",
      "table        |  0.360 |  0.554 âŒ\n",
      "chair        |  0.350 |  0.614 âŒ\n",
      "robot        |  0.228 |  0.726 âœ…\n",
      "backpack     |  0.043 |  0.581 âŒ\n",
      "free         |  0.533 |  0.832 âœ…\n",
      "laptop       |  0.320 |  0.573 âŒ\n",
      "bottle       |  0.120 |  0.569 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.3570 | Acc=0.6782\n",
      "ğŸ“‰ Train=3.827 | Val=10.115 | Gap=6.289 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.3h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 3.8439 - val_loss: 10.1154 - learning_rate: 3.1250e-06\n",
      "Epoch 111/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 3.8209 - val_loss: 10.7456 - learning_rate: 3.1250e-06\n",
      "Epoch 112/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - loss: 3.8115 - val_loss: 11.8149 - learning_rate: 3.1250e-06\n",
      "Epoch 113/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 56ms/step - loss: 3.8169 - val_loss: 10.7797 - learning_rate: 3.1250e-06\n",
      "Epoch 114/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 56ms/step - loss: 3.8219 - val_loss: 10.6368 - learning_rate: 3.1250e-06\n",
      "Epoch 115/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 56ms/step - loss: 3.7796 - val_loss: 11.1571 - learning_rate: 3.1250e-06\n",
      "Epoch 116/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 3.7986 - val_loss: 10.9733 - learning_rate: 3.1250e-06\n",
      "Epoch 117/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 3.7742 - val_loss: 10.4730 - learning_rate: 3.1250e-06\n",
      "Epoch 118/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 3.7626 - val_loss: 11.2586 - learning_rate: 3.1250e-06\n",
      "Epoch 119/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - loss: 3.7539 - val_loss: 12.0456 - learning_rate: 3.1250e-06\n",
      "Epoch 120/150\n",
      "\u001b[1m495/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 3.7589\n",
      "ğŸ’¾ Checkpoint saved: epoch 120\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 120/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.898 |  0.922 âœ…\n",
      "human        |  0.423 |  0.739 âœ…\n",
      "table        |  0.353 |  0.641 âŒ\n",
      "chair        |  0.358 |  0.645 âŒ\n",
      "robot        |  0.217 |  0.760 âœ…\n",
      "backpack     |  0.061 |  0.495 âŒ\n",
      "free         |  0.545 |  0.815 âœ…\n",
      "laptop       |  0.336 |  0.544 âŒ\n",
      "bottle       |  0.146 |  0.463 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.3707 | Acc=0.6695\n",
      "ğŸ“‰ Train=3.765 | Val=11.310 | Gap=7.546 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.2h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 90ms/step - loss: 3.7589 - val_loss: 11.3104 - learning_rate: 3.1250e-06\n",
      "Epoch 121/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.7432 - val_loss: 11.6451 - learning_rate: 3.1250e-06\n",
      "Epoch 122/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 3.7394 - val_loss: 11.6367 - learning_rate: 3.1250e-06\n",
      "Epoch 123/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 3.7311 - val_loss: 11.6034 - learning_rate: 3.1250e-06\n",
      "Epoch 124/150\n",
      "\u001b[1m495/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.7113\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 3.7113 - val_loss: 11.1208 - learning_rate: 3.1250e-06\n",
      "Epoch 125/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 49ms/step - loss: 3.7341 - val_loss: 11.6967 - learning_rate: 1.5625e-06\n",
      "Epoch 126/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - loss: 3.7204 - val_loss: 11.0194 - learning_rate: 1.5625e-06\n",
      "Epoch 127/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 3.6913 - val_loss: 11.6348 - learning_rate: 1.5625e-06\n",
      "Epoch 128/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.6915 - val_loss: 11.5550 - learning_rate: 1.5625e-06\n",
      "Epoch 129/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.6938 - val_loss: 11.3058 - learning_rate: 1.5625e-06\n",
      "Epoch 130/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.6870\n",
      "ğŸ’¾ Checkpoint saved: epoch 130\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 130/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.870 |  0.892 âœ…\n",
      "human        |  0.396 |  0.780 âœ…\n",
      "table        |  0.365 |  0.556 âŒ\n",
      "chair        |  0.352 |  0.592 âŒ\n",
      "robot        |  0.238 |  0.718 âœ…\n",
      "backpack     |  0.042 |  0.563 âŒ\n",
      "free         |  0.535 |  0.828 âœ…\n",
      "laptop       |  0.331 |  0.515 âŒ\n",
      "bottle       |  0.115 |  0.586 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.3605 | Acc=0.6701\n",
      "ğŸ“‰ Train=3.684 | Val=11.765 | Gap=8.081 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.2h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 89ms/step - loss: 3.6870 - val_loss: 11.7654 - learning_rate: 1.5625e-06\n",
      "Epoch 131/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 3.6951 - val_loss: 11.4194 - learning_rate: 1.5625e-06\n",
      "Epoch 132/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 56ms/step - loss: 3.6769 - val_loss: 11.6563 - learning_rate: 1.5625e-06\n",
      "Epoch 133/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.6670 - val_loss: 11.7919 - learning_rate: 1.5625e-06\n",
      "Epoch 134/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.6842 - val_loss: 11.7664 - learning_rate: 1.5625e-06\n",
      "Epoch 135/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 3.6873 - val_loss: 11.3717 - learning_rate: 1.5625e-06\n",
      "Epoch 136/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 3.6724 - val_loss: 11.8032 - learning_rate: 1.5625e-06\n",
      "Epoch 137/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 3.6390 - val_loss: 11.8603 - learning_rate: 1.5625e-06\n",
      "Epoch 138/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - loss: 3.6513 - val_loss: 11.6144 - learning_rate: 1.5625e-06\n",
      "Epoch 139/150\n",
      "\u001b[1m495/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.6667\n",
      "Epoch 139: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - loss: 3.6667 - val_loss: 11.5368 - learning_rate: 1.5625e-06\n",
      "Epoch 140/150\n",
      "\u001b[1m495/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 3.6393\n",
      "ğŸ’¾ Checkpoint saved: epoch 140\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 140/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.891 |  0.916 âœ…\n",
      "human        |  0.428 |  0.758 âœ…\n",
      "table        |  0.363 |  0.614 âŒ\n",
      "chair        |  0.360 |  0.644 âŒ\n",
      "robot        |  0.241 |  0.724 âœ…\n",
      "backpack     |  0.057 |  0.512 âŒ\n",
      "free         |  0.544 |  0.821 âœ…\n",
      "laptop       |  0.332 |  0.511 âŒ\n",
      "bottle       |  0.135 |  0.509 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.3724 | Acc=0.6676\n",
      "ğŸ“‰ Train=3.632 | Val=11.968 | Gap=8.336 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.1h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 96ms/step - loss: 3.6393 - val_loss: 11.9682 - learning_rate: 7.8125e-07\n",
      "Epoch 141/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 59ms/step - loss: 3.6709 - val_loss: 11.9628 - learning_rate: 7.8125e-07\n",
      "Epoch 142/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - loss: 3.6337 - val_loss: 12.0395 - learning_rate: 7.8125e-07\n",
      "Epoch 143/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.6410 - val_loss: 11.7225 - learning_rate: 7.8125e-07\n",
      "Epoch 144/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - loss: 3.6467 - val_loss: 11.8833 - learning_rate: 7.8125e-07\n",
      "Epoch 145/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 3.6181 - val_loss: 12.0946 - learning_rate: 7.8125e-07\n",
      "Epoch 146/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 3.6383 - val_loss: 12.0440 - learning_rate: 7.8125e-07\n",
      "Epoch 147/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - loss: 3.6306 - val_loss: 11.8536 - learning_rate: 7.8125e-07\n",
      "Epoch 148/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 3.6078 - val_loss: 11.8478 - learning_rate: 7.8125e-07\n",
      "Epoch 149/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 56ms/step - loss: 3.6157 - val_loss: 11.8566 - learning_rate: 7.8125e-07\n",
      "Epoch 150/150\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.6359\n",
      "ğŸ’¾ Checkpoint saved: epoch 150\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š EPOCH 150/150\n",
      "\n",
      "Class        |    IoU |    Acc\n",
      "-----------------------------------\n",
      "background   |  0.887 |  0.911 âœ…\n",
      "human        |  0.429 |  0.757 âœ…\n",
      "table        |  0.365 |  0.606 âŒ\n",
      "chair        |  0.361 |  0.629 âŒ\n",
      "robot        |  0.238 |  0.730 âœ…\n",
      "backpack     |  0.055 |  0.521 âŒ\n",
      "free         |  0.545 |  0.830 âœ…\n",
      "laptop       |  0.332 |  0.532 âŒ\n",
      "bottle       |  0.133 |  0.522 âŒ\n",
      "-----------------------------------\n",
      "Mean: IoU=0.3717 | Acc=0.6710\n",
      "ğŸ“‰ Train=3.633 | Val=11.610 | Gap=7.977 âš ï¸\n",
      "â±ï¸ 29s/epoch | 0.0h left\n",
      "======================================================================\n",
      "\n",
      "\u001b[1m496/496\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 89ms/step - loss: 3.6359 - val_loss: 11.6099 - learning_rate: 7.8125e-07\n",
      "\n",
      "âœ… TRAINING COMPLETED!\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Class        |      IoU |        Acc | Prev IoU | Change\n",
      "-----------------------------------------------------------------\n",
      "background   |   0.8873 |     0.9112 |     0.05 | +0.837 âœ…\n",
      "human        |   0.4285 |     0.7570 |     0.03 | +0.399 âœ…\n",
      "table        |   0.3655 |     0.6064 |     0.07 | +0.295 âŒ\n",
      "chair        |   0.3614 |     0.6291 |     0.17 | +0.191 âŒ\n",
      "robot        |   0.2380 |     0.7301 |     0.03 | +0.208 âœ…\n",
      "backpack     |   0.0549 |     0.5210 |     0.01 | +0.045 âŒ\n",
      "free         |   0.5445 |     0.8296 |     0.28 | +0.265 âœ…\n",
      "laptop       |   0.3321 |     0.5322 |     0.05 | +0.282 âŒ\n",
      "bottle       |   0.1328 |     0.5223 |     0.04 | +0.093 âŒ\n",
      "-----------------------------------------------------------------\n",
      "Mean IoU: 0.3717 (was 0.082)\n",
      "Mean Acc: 0.6710\n",
      "\n",
      "âœ… Classes â‰¥70%: 4/9 (was 2/9)\n",
      "ğŸ“‰ Final gap: 7.977 (was ~7.0)\n",
      "================================================================================\n",
      "\n",
      "ğŸ’¾ Saved: /home/frauas/segmentation219_AIS/checkpoints_emergency_fix/final_model.keras\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ†˜ EMERGENCY FIX COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbff54ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ ULTRA-FAST 70%+ ACCURACY TRAINING\n",
      "================================================================================\n",
      "âš¡ Optimizations:\n",
      "   - Mixed precision (FP16): 2x faster\n",
      "   - Reduced oversampling: 3x fewer steps\n",
      "   - Larger batch size: Better GPU utilization\n",
      "   - Fewer validation steps: Faster evaluation\n",
      "================================================================================\n",
      "\n",
      "âœ… Fast config: Batch=32, Epochs=50\n",
      "\n",
      "ğŸ“‚ Loading datasets...\n",
      "âœ… Datasets loaded\n",
      "\n",
      "ğŸ”„ Creating optimized balanced dataset...\n",
      "âœ… Optimized dataset: Robot 8x, Backpack 8x, Human 5x, Bottle 4x\n",
      "\n",
      "ğŸ”¨ Building optimized model...\n",
      "âœ… Model: 5,708,161 parameters (optimized)\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ STARTING FAST TRAINING\n",
      "================================================================================\n",
      "âš¡ Expected: 3-5 minutes per epoch (3-5x faster!)\n",
      "================================================================================\n",
      "\n",
      "â° Started: 16:12:52\n",
      "\n",
      "Epoch 1/50\n",
      "    980/Unknown \u001b[1m397s\u001b[0m 70ms/step - loss: 11.9071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frauas/segmentation219_AIS/scripts/ais_env/lib/python3.9/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 76ms/step - loss: 11.9041 - val_loss: 20.2544 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 79ms/step - loss: 10.2583 - val_loss: 28.9391 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 80ms/step - loss: 9.7204 - val_loss: 8.6383 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 76ms/step - loss: 9.5256 - val_loss: 8.7540 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 77ms/step - loss: 8.8731 - val_loss: 9.8761 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 82ms/step - loss: 8.8468 - val_loss: 10.6382 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 82ms/step - loss: 8.6910 - val_loss: 9.8280 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 81ms/step - loss: 9.0951 - val_loss: 8.0438 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 79ms/step - loss: 8.4356 - val_loss: 8.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m979/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 8.0475ğŸ’¾ Saved: epoch 10\n",
      "\n",
      "===========================================================================\n",
      "ğŸ“Š EPOCH 10/50\n",
      "===========================================================================\n",
      "\n",
      "Class        |    IoU |    Acc |  Target |    Gap\n",
      "------------------------------------------------------------\n",
      "background   |  0.792 |  0.832 |     0.7 |   PASS âœ… \n",
      "human        |  0.142 |  0.290 |     0.7 | -41.0% âŒ â­\n",
      "table        |  0.021 |  0.036 |     0.7 | -66.4% âŒ \n",
      "chair        |  0.214 |  0.382 |     0.7 | -31.8% âŒ \n",
      "robot        |  0.065 |  0.258 |     0.7 | -44.2% âŒ â­\n",
      "backpack     |  0.005 |  0.059 |     0.7 | -64.1% âŒ â­\n",
      "free         |  0.260 |  0.708 |     0.7 |   PASS âœ… \n",
      "laptop       |  0.032 |  0.157 |     0.7 | -54.3% âŒ \n",
      "bottle       |  0.002 |  0.002 |     0.7 | -69.8% âŒ â­\n",
      "------------------------------------------------------------\n",
      "Mean: IoU=0.1703 | Acc=0.3025\n",
      "\n",
      "ğŸ¯ Progress: 2/9 classes â‰¥70% ğŸ‰ IMPROVED!\n",
      "ğŸ“‰ Gap=3.774 âš ï¸\n",
      "â±ï¸ 211 min left\n",
      "===========================================================================\n",
      "\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 98ms/step - loss: 8.0462 - val_loss: 10.5129 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 84ms/step - loss: 7.9669 - val_loss: 7.8288 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 83ms/step - loss: 7.8387 - val_loss: 7.7600 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 80ms/step - loss: 7.5865 - val_loss: 9.2837 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 83ms/step - loss: 7.7092 - val_loss: 8.5831 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 82ms/step - loss: 7.3912 - val_loss: 8.6938 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 80ms/step - loss: 7.3548 - val_loss: 7.6270 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 79ms/step - loss: 7.1974 - val_loss: 8.2204 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 85ms/step - loss: 7.2291 - val_loss: 7.4865 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 84ms/step - loss: 7.1323 - val_loss: 35.1479 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m978/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 7.0576ğŸ’¾ Saved: epoch 20\n",
      "\n",
      "===========================================================================\n",
      "ğŸ“Š EPOCH 20/50\n",
      "===========================================================================\n",
      "\n",
      "Class        |    IoU |    Acc |  Target |    Gap\n",
      "------------------------------------------------------------\n",
      "background   |  0.714 |  0.737 |     0.7 |   PASS âœ… \n",
      "human        |  0.133 |  0.302 |     0.7 | -39.8% âŒ â­\n",
      "table        |  0.077 |  0.206 |     0.7 | -49.4% âŒ \n",
      "chair        |  0.162 |  0.211 |     0.7 | -48.9% âŒ \n",
      "robot        |  0.050 |  0.494 |     0.7 | -20.6% âŒ â­\n",
      "backpack     |  0.013 |  0.346 |     0.7 | -35.4% âŒ â­\n",
      "free         |  0.329 |  0.717 |     0.7 |   PASS âœ… \n",
      "laptop       |  0.068 |  0.500 |     0.7 | -20.0% âŒ \n",
      "bottle       |  0.004 |  0.005 |     0.7 | -69.5% âŒ â­\n",
      "------------------------------------------------------------\n",
      "Mean: IoU=0.1723 | Acc=0.3909\n",
      "\n",
      "ğŸ¯ Progress: 2/9 classes â‰¥70%\n",
      "ğŸ“‰ Gap=1.779 ğŸŸ¡\n",
      "â±ï¸ 157 min left\n",
      "===========================================================================\n",
      "\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 92ms/step - loss: 7.0560 - val_loss: 8.0814 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 83ms/step - loss: 7.0506 - val_loss: 7.6616 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 84ms/step - loss: 7.0175 - val_loss: 7.9829 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 83ms/step - loss: 6.9839 - val_loss: 7.4788 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 85ms/step - loss: 6.9175 - val_loss: 7.4115 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 80ms/step - loss: 6.9692 - val_loss: 14.5347 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 77ms/step - loss: 6.8834 - val_loss: 7.7815 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 85ms/step - loss: 6.8536 - val_loss: 8.2196 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 89ms/step - loss: 6.7607 - val_loss: 7.9657 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 82ms/step - loss: 6.8662 - val_loss: 12.4567 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m978/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 6.7520ğŸ’¾ Saved: epoch 30\n",
      "\n",
      "===========================================================================\n",
      "ğŸ“Š EPOCH 30/50\n",
      "===========================================================================\n",
      "\n",
      "Class        |    IoU |    Acc |  Target |    Gap\n",
      "------------------------------------------------------------\n",
      "background   |  0.777 |  0.808 |     0.7 |   PASS âœ… \n",
      "human        |  0.108 |  0.132 |     0.7 | -56.8% âŒ â­\n",
      "table        |  0.089 |  0.282 |     0.7 | -41.8% âŒ \n",
      "chair        |  0.203 |  0.530 |     0.7 | -17.0% âŒ \n",
      "robot        |  0.071 |  0.164 |     0.7 | -53.6% âŒ â­\n",
      "backpack     |  0.009 |  0.087 |     0.7 | -61.3% âŒ â­\n",
      "free         |  0.315 |  0.737 |     0.7 |   PASS âœ… \n",
      "laptop       |  0.078 |  0.424 |     0.7 | -27.6% âŒ \n",
      "bottle       |  0.009 |  0.016 |     0.7 | -68.4% âŒ â­\n",
      "------------------------------------------------------------\n",
      "Mean: IoU=0.1845 | Acc=0.3533\n",
      "\n",
      "ğŸ¯ Progress: 2/9 classes â‰¥70%\n",
      "ğŸ“‰ Gap=2.954 âš ï¸\n",
      "â±ï¸ 105 min left\n",
      "===========================================================================\n",
      "\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 104ms/step - loss: 6.7508 - val_loss: 9.1097 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 84ms/step - loss: 6.7833 - val_loss: 7.4817 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 86ms/step - loss: 6.6989 - val_loss: 9.1477 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 92ms/step - loss: 6.8203 - val_loss: 7.6316 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m979/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 6.6932\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 84ms/step - loss: 6.6920 - val_loss: 7.7614 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 84ms/step - loss: 6.6771 - val_loss: 7.5021 - learning_rate: 5.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 87ms/step - loss: 6.6553 - val_loss: 7.4320 - learning_rate: 5.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 110ms/step - loss: 6.6941 - val_loss: 7.5214 - learning_rate: 5.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 146ms/step - loss: 6.6182 - val_loss: 7.4529 - learning_rate: 5.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 95ms/step - loss: 6.6129 - val_loss: 7.7073 - learning_rate: 5.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 6.6318ğŸ’¾ Saved: epoch 40\n",
      "\n",
      "===========================================================================\n",
      "ğŸ“Š EPOCH 40/50\n",
      "===========================================================================\n",
      "\n",
      "Class        |    IoU |    Acc |  Target |    Gap\n",
      "------------------------------------------------------------\n",
      "background   |  0.751 |  0.778 |     0.7 |   PASS âœ… \n",
      "human        |  0.141 |  0.204 |     0.7 | -49.6% âŒ â­\n",
      "table        |  0.116 |  0.256 |     0.7 | -44.4% âŒ \n",
      "chair        |  0.219 |  0.498 |     0.7 | -20.2% âŒ \n",
      "robot        |  0.099 |  0.302 |     0.7 | -39.8% âŒ â­\n",
      "backpack     |  0.010 |  0.084 |     0.7 | -61.6% âŒ â­\n",
      "free         |  0.355 |  0.775 |     0.7 |   PASS âœ… \n",
      "laptop       |  0.075 |  0.495 |     0.7 | -20.5% âŒ \n",
      "bottle       |  0.004 |  0.005 |     0.7 | -69.5% âŒ â­\n",
      "------------------------------------------------------------\n",
      "Mean: IoU=0.1965 | Acc=0.3774\n",
      "\n",
      "ğŸ¯ Progress: 2/9 classes â‰¥70%\n",
      "ğŸ“‰ Gap=1.622 ğŸŸ¡\n",
      "â±ï¸ 54 min left\n",
      "===========================================================================\n",
      "\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 109ms/step - loss: 6.6314 - val_loss: 7.7796 - learning_rate: 5.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 99ms/step - loss: 6.6835 - val_loss: 7.3207 - learning_rate: 5.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 96ms/step - loss: 6.5885 - val_loss: 7.5245 - learning_rate: 5.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 96ms/step - loss: 6.5450 - val_loss: 7.6328 - learning_rate: 5.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 96ms/step - loss: 6.5468 - val_loss: 7.9469 - learning_rate: 5.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 97ms/step - loss: 6.5536 - val_loss: 7.6207 - learning_rate: 5.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 102ms/step - loss: 6.5313 - val_loss: 8.2027 - learning_rate: 5.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 95ms/step - loss: 6.5339 - val_loss: 7.6971 - learning_rate: 5.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 93ms/step - loss: 6.4879 - val_loss: 7.6709 - learning_rate: 5.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 89ms/step - loss: 6.4557 - val_loss: 7.5342 - learning_rate: 5.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m978/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 6.4900ğŸ’¾ Saved: epoch 50\n",
      "\n",
      "===========================================================================\n",
      "ğŸ“Š EPOCH 50/50\n",
      "===========================================================================\n",
      "\n",
      "Class        |    IoU |    Acc |  Target |    Gap\n",
      "------------------------------------------------------------\n",
      "background   |  0.772 |  0.800 |     0.7 |   PASS âœ… \n",
      "human        |  0.102 |  0.124 |     0.7 | -57.6% âŒ â­\n",
      "table        |  0.103 |  0.449 |     0.7 | -25.1% âŒ \n",
      "chair        |  0.242 |  0.541 |     0.7 | -15.9% âŒ \n",
      "robot        |  0.097 |  0.267 |     0.7 | -43.3% âŒ â­\n",
      "backpack     |  0.010 |  0.116 |     0.7 | -58.4% âŒ â­\n",
      "free         |  0.373 |  0.774 |     0.7 |   PASS âœ… \n",
      "laptop       |  0.081 |  0.467 |     0.7 | -23.3% âŒ \n",
      "bottle       |  0.007 |  0.010 |     0.7 | -69.0% âŒ â­\n",
      "------------------------------------------------------------\n",
      "Mean: IoU=0.1985 | Acc=0.3943\n",
      "\n",
      "ğŸ¯ Progress: 2/9 classes â‰¥70%\n",
      "ğŸ“‰ Gap=1.536 ğŸŸ¡\n",
      "â±ï¸ 0 min left\n",
      "===========================================================================\n",
      "\n",
      "\u001b[1m980/980\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 107ms/step - loss: 6.4892 - val_loss: 7.6106 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\n",
      "âœ… TRAINING COMPLETE!\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Class        |      IoU |   Accuracy | Status\n",
      "-------------------------------------------------------\n",
      "background   |   0.7043 |     72.47% | âœ… PASS\n",
      "human        |   0.2060 |     37.30% | âŒ FAIL\n",
      "table        |   0.1104 |     33.85% | âŒ FAIL\n",
      "chair        |   0.2358 |     51.84% | âŒ FAIL\n",
      "robot        |   0.1039 |     36.65% | âŒ FAIL\n",
      "backpack     |   0.0101 |     13.34% | âŒ FAIL\n",
      "free         |   0.3450 |     78.78% | âœ… PASS\n",
      "laptop       |   0.0741 |     58.60% | âŒ FAIL\n",
      "bottle       |   0.0034 |      0.38% | âŒ FAIL\n",
      "-------------------------------------------------------\n",
      "\n",
      "ğŸ¯ FINAL: 2/9 classes â‰¥70%\n",
      "Mean IoU: 0.1992\n",
      "Mean Acc: 42.58%\n",
      "================================================================================\n",
      "\n",
      "ğŸ’¾ Saved\n",
      "ğŸ‰ COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ULTRA-FAST 70%+ TRAINING - 3-5X SPEEDUP\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=2\"\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Enable mixed precision for 2x speedup\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ ULTRA-FAST 70%+ ACCURACY TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(\"âš¡ Optimizations:\")\n",
    "print(\"   - Mixed precision (FP16): 2x faster\")\n",
    "print(\"   - Reduced oversampling: 3x fewer steps\")\n",
    "print(\"   - Larger batch size: Better GPU utilization\")\n",
    "print(\"   - Fewer validation steps: Faster evaluation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# =========================================================\n",
    "# OPTIMIZED CONFIGURATION\n",
    "# =========================================================\n",
    "NUM_CLASSES = 9\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32  # â† Increased from 20 (better GPU usage)\n",
    "EPOCHS = 50\n",
    "LR_INITIAL = 1e-4\n",
    "LR_MIN = 1e-7\n",
    "\n",
    "CHECKPOINT_DIR = \"/home/frauas/segmentation219_AIS/checkpoints_fast_70percent\"\n",
    "CHECKPOINT_FREQ = 10\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "DATASET_PATH = \"/home/frauas/segmentation219_AIS/data/frauas_10classes/tfrecords_9class\"\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"background\", \"human\", \"table\", \"chair\", \"robot\", \n",
    "    \"backpack\", \"free\", \"laptop\", \"bottle\"\n",
    "]\n",
    "\n",
    "CLASS_WEIGHTS = tf.constant([\n",
    "    1.0, 30.0, 30.0, 35.0, 250.0, 1500.0, 15.0, 80.0, 25.0\n",
    "], dtype=tf.float32)\n",
    "\n",
    "print(f\"\\nâœ… Fast config: Batch={BATCH_SIZE}, Epochs={EPOCHS}\")\n",
    "\n",
    "# =========================================================\n",
    "# OPTIMIZED DATA PIPELINE\n",
    "# =========================================================\n",
    "feature_desc = {\n",
    "    \"rgb\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"x\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"y\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"z\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def remap_labels(label):\n",
    "    remapped = tf.where(label == 8, 7, label)\n",
    "    remapped = tf.where(label == 9, 8, remapped)\n",
    "    return remapped\n",
    "\n",
    "@tf.function\n",
    "def parse_example(example):\n",
    "    ex = tf.io.parse_single_example(example, feature_desc)\n",
    "    rgb = tf.image.decode_jpeg(ex[\"rgb\"], channels=3)\n",
    "    x = tf.image.decode_jpeg(ex[\"x\"], channels=1)\n",
    "    y = tf.image.decode_jpeg(ex[\"y\"], channels=1)\n",
    "    z = tf.image.decode_jpeg(ex[\"z\"], channels=1)\n",
    "    rgb = tf.image.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
    "    x = tf.image.resize(x, (IMG_SIZE, IMG_SIZE))\n",
    "    y = tf.image.resize(y, (IMG_SIZE, IMG_SIZE))\n",
    "    z = tf.image.resize(z, (IMG_SIZE, IMG_SIZE))\n",
    "    rgb = tf.cast(rgb, tf.float32) / 255.0\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    y = tf.cast(y, tf.float32) / 255.0\n",
    "    z = tf.cast(z, tf.float32) / 255.0\n",
    "    rgbxyz = tf.concat([rgb, x, y, z], axis=-1)\n",
    "    label = tf.image.decode_png(ex[\"label\"], channels=1)\n",
    "    label = tf.image.resize(label, (IMG_SIZE, IMG_SIZE), method=\"nearest\")\n",
    "    label = tf.squeeze(label, -1)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    label = remap_labels(label)\n",
    "    label = tf.clip_by_value(label, 0, NUM_CLASSES - 1)\n",
    "    return rgbxyz, label\n",
    "\n",
    "@tf.function\n",
    "def fast_augment(rgbxyz, label):\n",
    "    # Simplified augmentation for speed\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        rgbxyz = tf.image.flip_left_right(rgbxyz)\n",
    "        label = tf.image.flip_left_right(label[..., tf.newaxis])[..., 0]\n",
    "    rgb = rgbxyz[..., :3]\n",
    "    xyz = rgbxyz[..., 3:]\n",
    "    rgb = tf.image.random_brightness(rgb, 0.2)\n",
    "    rgb = tf.image.random_contrast(rgb, 0.8, 1.2)\n",
    "    rgb = tf.clip_by_value(rgb, 0.0, 1.0)\n",
    "    rgbxyz = tf.concat([rgb, xyz], axis=-1)\n",
    "    return rgbxyz, label\n",
    "\n",
    "def load_dataset(split, augment_data=False):\n",
    "    pattern = os.path.join(DATASET_PATH, split, \"*.tfrecords\")\n",
    "    file_list = glob.glob(pattern)\n",
    "    if not file_list:\n",
    "        raise ValueError(f\"No TFRecords at: {pattern}\")\n",
    "    if split == \"train\":\n",
    "        import random\n",
    "        random.shuffle(file_list)\n",
    "    ds = tf.data.TFRecordDataset(file_list, num_parallel_reads=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if split == \"val\":\n",
    "        ds = ds.cache()\n",
    "    if augment_data:\n",
    "        ds = ds.map(fast_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if split == \"train\":\n",
    "        ds = ds.shuffle(buffer_size=500)\n",
    "    ds = ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "print(\"\\nğŸ“‚ Loading datasets...\")\n",
    "train_ds = load_dataset(\"train\", augment_data=True)\n",
    "val_ds = load_dataset(\"val\", augment_data=False)\n",
    "print(\"âœ… Datasets loaded\")\n",
    "\n",
    "# =========================================================\n",
    "# OPTIMIZED OVERSAMPLING - REDUCED FROM 20x TO 5-8x\n",
    "# =========================================================\n",
    "print(\"\\nğŸ”„ Creating optimized balanced dataset...\")\n",
    "\n",
    "def has_class(class_id):\n",
    "    def filter_fn(images, labels):\n",
    "        return tf.reduce_any(tf.equal(labels, class_id))\n",
    "    return filter_fn\n",
    "\n",
    "train_ds_unbatched = train_ds.unbatch()\n",
    "\n",
    "robot_ds = train_ds_unbatched.filter(has_class(4))\n",
    "backpack_ds = train_ds_unbatched.filter(has_class(5))\n",
    "human_ds = train_ds_unbatched.filter(has_class(1))\n",
    "bottle_ds = train_ds_unbatched.filter(has_class(8))\n",
    "\n",
    "regular_ds = train_ds_unbatched.filter(\n",
    "    lambda img, lbl: tf.logical_not(\n",
    "        tf.reduce_any(tf.equal(lbl, 4)) | \n",
    "        tf.reduce_any(tf.equal(lbl, 5)) |\n",
    "        tf.reduce_any(tf.equal(lbl, 1)) |\n",
    "        tf.reduce_any(tf.equal(lbl, 8))\n",
    "    )\n",
    ")\n",
    "\n",
    "# REDUCED oversampling for speed\n",
    "robot_repeated = robot_ds.repeat(8)      # 8x instead of 20x\n",
    "backpack_repeated = backpack_ds.repeat(8) # 8x instead of 20x\n",
    "human_repeated = human_ds.repeat(5)       # 5x instead of 10x\n",
    "bottle_repeated = bottle_ds.repeat(4)     # 4x instead of 8x\n",
    "\n",
    "train_ds_balanced = robot_repeated.concatenate(backpack_repeated)\n",
    "train_ds_balanced = train_ds_balanced.concatenate(human_repeated)\n",
    "train_ds_balanced = train_ds_balanced.concatenate(bottle_repeated)\n",
    "train_ds_balanced = train_ds_balanced.concatenate(regular_ds)\n",
    "\n",
    "train_ds_balanced = train_ds_balanced.shuffle(buffer_size=1000)\n",
    "train_ds_balanced = train_ds_balanced.batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_ds_balanced = train_ds_balanced.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"âœ… Optimized dataset: Robot 8x, Backpack 8x, Human 5x, Bottle 4x\")\n",
    "\n",
    "# =========================================================\n",
    "# LIGHTER MODEL FOR SPEED\n",
    "# =========================================================\n",
    "def conv_block(x, filters, dropout_rate=0.0):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, 3, padding=\"same\", use_bias=False,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(5e-4)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, 3, padding=\"same\", use_bias=False,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(5e-4)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    if dropout_rate > 0:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def unet_rgbd_fast():\n",
    "    inputs = tf.keras.Input((IMG_SIZE, IMG_SIZE, 6))\n",
    "    \n",
    "    # Lighter encoder\n",
    "    c1 = conv_block(inputs, 48)\n",
    "    p1 = tf.keras.layers.MaxPooling2D()(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, 96)\n",
    "    p2 = tf.keras.layers.MaxPooling2D()(c2)\n",
    "    \n",
    "    c3 = conv_block(p2, 192)\n",
    "    p3 = tf.keras.layers.MaxPooling2D()(c3)\n",
    "    \n",
    "    c4 = conv_block(p3, 256, dropout_rate=0.4)  # Reduced from 384\n",
    "    p4 = tf.keras.layers.MaxPooling2D()(c4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c5 = conv_block(p4, 256, dropout_rate=0.5)  # Reduced from 384\n",
    "    \n",
    "    # Decoder\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(c5)  # Reduced from 192\n",
    "    u6 = tf.keras.layers.Concatenate()([u6, c4])\n",
    "    c6 = conv_block(u6, 256, dropout_rate=0.4)\n",
    "    \n",
    "    u7 = tf.keras.layers.Conv2DTranspose(96, 2, strides=2, padding=\"same\")(c6)\n",
    "    u7 = tf.keras.layers.Concatenate()([u7, c3])\n",
    "    c7 = conv_block(u7, 192, dropout_rate=0.3)\n",
    "    \n",
    "    u8 = tf.keras.layers.Conv2DTranspose(48, 2, strides=2, padding=\"same\")(c7)\n",
    "    u8 = tf.keras.layers.Concatenate()([u8, c2])\n",
    "    c8 = conv_block(u8, 96, dropout_rate=0.2)\n",
    "    \n",
    "    u9 = tf.keras.layers.Conv2DTranspose(24, 2, strides=2, padding=\"same\")(c8)\n",
    "    u9 = tf.keras.layers.Concatenate()([u9, c1])\n",
    "    c9 = conv_block(u9, 48)\n",
    "    \n",
    "    # Mixed precision compatible output\n",
    "    outputs = tf.keras.layers.Conv2D(NUM_CLASSES, 1, activation=\"softmax\", dtype='float32')(c9)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "print(\"\\nğŸ”¨ Building optimized model...\")\n",
    "model = unet_rgbd_fast()\n",
    "\n",
    "def weighted_focal_loss(y_true, y_pred, gamma=4.0):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    pt = tf.exp(-ce)\n",
    "    focal = (1 - pt) ** gamma\n",
    "    weights = tf.gather(CLASS_WEIGHTS, y_true)\n",
    "    return tf.reduce_mean(weights * focal * ce)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true_oh = tf.one_hot(y_true, NUM_CLASSES)\n",
    "    y_true_fg = y_true_oh[..., 1:]\n",
    "    y_pred_fg = y_pred[..., 1:]\n",
    "    inter = tf.reduce_sum(y_true_fg * y_pred_fg, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true_fg + y_pred_fg, axis=[1, 2, 3])\n",
    "    dice = (2 * inter + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return weighted_focal_loss(y_true, y_pred) + 6.0 * dice_loss(y_true, y_pred)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(LR_INITIAL),\n",
    "    loss=combined_loss,\n",
    "    run_eagerly=False,\n",
    "    jit_compile=True  # XLA compilation for speed\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model: {model.count_params():,} parameters (optimized)\")\n",
    "\n",
    "def save_checkpoint(model, epoch, train_info):\n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch:04d}.keras\")\n",
    "    model.save(checkpoint_path)\n",
    "    metadata_path = os.path.join(CHECKPOINT_DIR, f\"metadata_epoch_{epoch:04d}.json\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(train_info, f, indent=2)\n",
    "    print(f\"ğŸ’¾ Saved: epoch {epoch}\")\n",
    "    all_checkpoints = sorted(glob.glob(os.path.join(CHECKPOINT_DIR, \"checkpoint_epoch_*.keras\")))\n",
    "    if len(all_checkpoints) > 3:\n",
    "        for old_checkpoint in all_checkpoints[:-3]:\n",
    "            os.remove(old_checkpoint)\n",
    "            old_meta = old_checkpoint.replace(\"checkpoint_\", \"metadata_\").replace(\".keras\", \".json\")\n",
    "            if os.path.exists(old_meta):\n",
    "                os.remove(old_meta)\n",
    "\n",
    "def compute_metrics(model, dataset):\n",
    "    intersection = np.zeros(NUM_CLASSES)\n",
    "    union = np.zeros(NUM_CLASSES)\n",
    "    correct_pixels = np.zeros(NUM_CLASSES)\n",
    "    total_pixels = np.zeros(NUM_CLASSES)\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images, verbose=0)\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "        labels = labels.numpy()\n",
    "        for c in range(NUM_CLASSES):\n",
    "            pred_c = (preds == c)\n",
    "            label_c = (labels == c)\n",
    "            intersection[c] += np.logical_and(pred_c, label_c).sum()\n",
    "            union[c] += np.logical_or(pred_c, label_c).sum()\n",
    "            correct_pixels[c] += np.logical_and(pred_c, label_c).sum()\n",
    "            total_pixels[c] += label_c.sum()\n",
    "    iou = intersection / (union + 1e-7)\n",
    "    accuracy = correct_pixels / (total_pixels + 1e-7)\n",
    "    return iou, accuracy\n",
    "\n",
    "class CheckpointCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_ds, checkpoint_freq=10, iou_freq=10):\n",
    "        super().__init__()\n",
    "        self.val_ds = val_ds\n",
    "        self.checkpoint_freq = checkpoint_freq\n",
    "        self.iou_freq = iou_freq\n",
    "        self.best_count_70 = 0\n",
    "        self.start_time = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = datetime.now()\n",
    "        print(f\"â° Started: {self.start_time.strftime('%H:%M:%S')}\\n\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        actual_epoch = epoch + 1\n",
    "        current_val_loss = logs.get('val_loss', float('inf'))\n",
    "        \n",
    "        if (epoch + 1) % self.checkpoint_freq == 0:\n",
    "            try:\n",
    "                current_lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "            except:\n",
    "                current_lr = float(LR_INITIAL)\n",
    "            train_info = {\n",
    "                'epoch': actual_epoch,\n",
    "                'train_loss': float(logs.get('loss', 0)),\n",
    "                'val_loss': float(current_val_loss),\n",
    "                'learning_rate': current_lr\n",
    "            }\n",
    "            save_checkpoint(self.model, actual_epoch, train_info)\n",
    "        \n",
    "        if (epoch + 1) % self.iou_freq == 0:\n",
    "            print(f\"\\n{'='*75}\")\n",
    "            print(f\"ğŸ“Š EPOCH {actual_epoch}/{EPOCHS}\")\n",
    "            print(f\"{'='*75}\")\n",
    "            iou_scores, acc_scores = compute_metrics(self.model, self.val_ds)\n",
    "            \n",
    "            print(f\"\\n{'Class':<12} | {'IoU':>6} | {'Acc':>6} | {'Target':>7} | {'Gap':>6}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            count_70 = 0\n",
    "            for i in range(NUM_CLASSES):\n",
    "                gap = 70.0 - (acc_scores[i] * 100)\n",
    "                if acc_scores[i] >= 0.7:\n",
    "                    status = \"âœ…\"\n",
    "                    gap_str = \"PASS\"\n",
    "                    count_70 += 1\n",
    "                else:\n",
    "                    status = \"âŒ\"\n",
    "                    gap_str = f\"-{gap:.1f}%\"\n",
    "                highlight = \"â­\" if i in [1, 4, 5, 8] else \"\"\n",
    "                print(f\"{CLASS_NAMES[i]:<12} | {iou_scores[i]:>6.3f} | {acc_scores[i]:>6.3f} | {0.7:>7.1f} | {gap_str:>6} {status} {highlight}\")\n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "            print(f\"Mean: IoU={iou_scores.mean():.4f} | Acc={acc_scores.mean():.4f}\")\n",
    "            print(f\"\\nğŸ¯ Progress: {count_70}/9 classes â‰¥70%\", end=\"\")\n",
    "            \n",
    "            if count_70 > self.best_count_70:\n",
    "                self.best_count_70 = count_70\n",
    "                print(\" ğŸ‰ IMPROVED!\")\n",
    "            else:\n",
    "                print()\n",
    "            \n",
    "            train_loss = logs.get('loss', 0)\n",
    "            gap_overfitting = current_val_loss - train_loss\n",
    "            print(f\"ğŸ“‰ Gap={gap_overfitting:.3f}\", end=\"\")\n",
    "            if gap_overfitting < 1.0:\n",
    "                print(\" âœ…\")\n",
    "            elif gap_overfitting < 2.0:\n",
    "                print(\" ğŸŸ¡\")\n",
    "            else:\n",
    "                print(\" âš ï¸\")\n",
    "            \n",
    "            elapsed = (datetime.now() - self.start_time).total_seconds()\n",
    "            remaining = (EPOCHS - actual_epoch) * elapsed / (epoch + 1)\n",
    "            print(f\"â±ï¸ {remaining/60:.0f} min left\")\n",
    "            print(f\"{'='*75}\\n\")\n",
    "\n",
    "callbacks = [\n",
    "    CheckpointCallback(val_ds, checkpoint_freq=10, iou_freq=10),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(CHECKPOINT_DIR, \"best_model.keras\"),\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        verbose=0\n",
    "    ),\n",
    "    tf.keras.callbacks.CSVLogger(\n",
    "        os.path.join(CHECKPOINT_DIR, \"training.csv\")\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=25,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=LR_MIN,\n",
    "        verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš€ STARTING FAST TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(\"âš¡ Expected: 3-5 minutes per epoch (3-5x faster!)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds_balanced,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=50,  # Reduced from 100 for speed\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… TRAINING COMPLETE!\")\n",
    "\n",
    "iou_scores, acc_scores = compute_metrics(model, val_ds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Class':<12} | {'IoU':>8} | {'Accuracy':>10} | Status\")\n",
    "print(\"-\"*55)\n",
    "\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    status = \"âœ… PASS\" if acc_scores[i] >= 0.7 else \"âŒ FAIL\"\n",
    "    print(f\"{name:<12} | {iou_scores[i]:>8.4f} | {acc_scores[i]*100:>9.2f}% | {status}\")\n",
    "\n",
    "print(\"-\"*55)\n",
    "classes_pass = np.sum(acc_scores >= 0.7)\n",
    "print(f\"\\nğŸ¯ FINAL: {classes_pass}/9 classes â‰¥70%\")\n",
    "print(f\"Mean IoU: {iou_scores.mean():.4f}\")\n",
    "print(f\"Mean Acc: {acc_scores.mean()*100:.2f}%\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "model.save(os.path.join(CHECKPOINT_DIR, \"final_model.keras\"))\n",
    "print(\"\\nğŸ’¾ Saved\\nğŸ‰ COMPLETE!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ais_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
